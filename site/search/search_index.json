{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SSIAMB","text":"<p>Welcome to the SSIAMB documentation!</p> <p>SSIAMB (SSI Ambiguous Site Detection Tool) is a bioinformatics tool for detecting and analyzing ambiguous sites in bacterial genomic sequences.</p>"},{"location":"#overview","title":"Overview","text":"<p>SSIAMB provides comprehensive analysis of ambiguous sites in genomic data by:</p> <ul> <li>Processing BAM alignment files to identify ambiguous sites</li> <li>Calculating depth and quality metrics</li> <li>Generating detailed reports and summaries</li> <li>Supporting multiple alignment and variant calling workflows</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install ssiamb\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code># Analyze a BAM file for ambiguous sites\nssiamb analyze sample.bam --reference ref.fasta --output results/\n\n# Process with custom thresholds\nssiamb analyze sample.bam --reference ref.fasta --min-depth 10 --min-quality 20\n</code></pre>"},{"location":"#features","title":"Features","text":"<ul> <li>Multi-format support: Works with BAM alignment files</li> <li>Flexible workflows: Compatible with BWA and Minimap2 aligners</li> <li>Quality control: Comprehensive depth and quality filtering</li> <li>Rich output: Detailed reports and summary statistics</li> <li>Galaxy integration: Available as a Galaxy tool</li> </ul>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>API Reference - Complete API documentation</li> <li>Galaxy Wrapper - Galaxy tool wrapper</li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>GitHub Issues - Bug reports and feature requests</li> <li>Repository - Source code and development</li> </ul>"},{"location":"reference/","title":"API Reference","text":"<p>This section contains the complete API reference for SSIAMB.</p>"},{"location":"reference/#cli-module","title":"CLI Module","text":"<p>ssiamb - SSI Ambiguous Site Detection Tool</p> <p>Command-line interface for detecting ambiguous sites in bacterial genomes through mapping and variant calling approaches.</p>"},{"location":"reference/#ssiamb.cli.main","title":"<code>main(version=None, config=None, verbose=False, quiet=False, dry_run=False)</code>","text":"<p>SSI Ambiguous Site Detection Tool.</p> <p>Detect ambiguous sites in bacterial genomes through mapping and variant calling.</p> Source code in <code>src/ssiamb/cli.py</code> <pre><code>@app.callback()\ndef main(\n    version: Annotated[\n        Optional[bool],\n        typer.Option(\n            \"--version\",\n            \"-V\",\n            help=\"Show version and exit\",\n            callback=version_callback,\n            is_eager=True,\n        ),\n    ] = None,\n    config: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"--config\",\n            \"-c\",\n            help=\"Path to custom configuration file\",\n            exists=True,\n            file_okay=True,\n            dir_okay=False,\n            readable=True,\n        ),\n    ] = None,\n    verbose: Annotated[\n        bool,\n        typer.Option(\n            \"--verbose\", \"-v\", help=\"Enable verbose output\"\n        ),\n    ] = False,\n    quiet: Annotated[\n        bool,\n        typer.Option(\n            \"--quiet\", \"-q\", help=\"Suppress non-error output\"\n        ),\n    ] = False,\n    dry_run: Annotated[\n        bool,\n        typer.Option(\n            \"--dry-run\", help=\"Show what would be done without executing\"\n        ),\n    ] = False,\n) -&gt; None:\n    \"\"\"\n    SSI Ambiguous Site Detection Tool.\n\n    Detect ambiguous sites in bacterial genomes through mapping and variant calling.\n    \"\"\"\n    if verbose and quiet:\n        console.print(\"[red]Error: --verbose and --quiet cannot be used together[/red]\")\n        raise typer.Exit(1)\n\n    # Load configuration if specified\n    if config:\n        from .config import load_config\n        try:\n            load_config(config)\n            if verbose:\n                console.print(f\"[green]Loaded configuration from: {config}[/green]\")\n        except Exception as e:\n            console.print(f\"[red]Error loading config file {config}: {e}[/red]\")\n            raise typer.Exit(1)\n</code></pre>"},{"location":"reference/#ssiamb.cli.ref","title":"<code>ref(ctx, r1, r2, reference=None, species=None, bracken=None, sample=None, output_dir=None, threads=4, mapper='minimap2', caller='bbtools', bbtools_mem=None, dp_min=10, maf_min=0.1, mapq=30, dp_cap=100, depth_tool=DepthTool.MOSDEPTH, require_pass=False, min_bracken_frac=0.7, min_bracken_reads=100000, ref_dir=None, on_fail='error', emit_vcf=False, emit_bed=False, emit_matrix=False, emit_per_contig=False, emit_multiqc=False, emit_provenance=False, tsv_mode=TSVMode.OVERWRITE, stdout=False)</code>","text":"<p>Reference-mapping mode: map reads to a reference genome.</p> <p>Maps paired-end reads to a reference genome to identify ambiguous sites. Reference can be provided directly, looked up by species, or selected from Bracken.</p> Source code in <code>src/ssiamb/cli.py</code> <pre><code>@app.command()\ndef ref(\n    ctx: typer.Context,\n    r1: Annotated[\n        Path,\n        typer.Option(\n            \"--r1\", help=\"Forward reads (FASTQ, can be gzipped)\"\n        ),\n    ],\n    r2: Annotated[\n        Path,\n        typer.Option(\n            \"--r2\", help=\"Reverse reads (FASTQ, can be gzipped)\"\n        ),\n    ],\n    reference: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"--reference\", help=\"Reference genome FASTA file\"\n        ),\n    ] = None,\n    species: Annotated[\n        Optional[str],\n        typer.Option(\n            \"--species\", help=\"Species name for reference lookup\"\n        ),\n    ] = None,\n    bracken: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"--bracken\", help=\"Bracken classification file\"\n        ),\n    ] = None,\n    sample: Annotated[\n        Optional[str],\n        typer.Option(\n            \"--sample\", help=\"Sample name (inferred from filenames if not provided)\"\n        ),\n    ] = None,\n    output_dir: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"--outdir\", \"-o\", help=\"Output directory (default: current)\"\n        ),\n    ] = None,\n    threads: Annotated[\n        int,\n        typer.Option(\n            \"--threads\", \"-t\", help=\"Number of threads\"\n        ),\n    ] = 4,\n    mapper: Annotated[\n        str,\n        typer.Option(\n            \"--mapper\", help=\"Mapper to use\"\n        ),\n    ] = \"minimap2\",\n    caller: Annotated[\n        str,\n        typer.Option(\n            \"--caller\", help=\"Variant caller to use\"\n        ),\n    ] = \"bbtools\",\n    bbtools_mem: Annotated[\n        Optional[str],\n        typer.Option(\n            \"--bbtools-mem\", help=\"BBTools heap memory (e.g., '4g', '8g')\"\n        ),\n    ] = None,\n    dp_min: Annotated[\n        int,\n        typer.Option(\n            \"--dp-min\", help=\"Minimum depth for ambiguous sites\"\n        ),\n    ] = 10,\n    maf_min: Annotated[\n        float,\n        typer.Option(\n            \"--maf-min\", help=\"Minimum minor allele frequency\"\n        ),\n    ] = 0.1,\n    mapq: Annotated[\n        int,\n        typer.Option(\n            \"--mapq\", help=\"Minimum mapping quality for depth analysis\"\n        ),\n    ] = 30,\n    dp_cap: Annotated[\n        int,\n        typer.Option(\n            \"--dp-cap\", help=\"Maximum depth cap for variant analysis\"\n        ),\n    ] = 100,\n    depth_tool: Annotated[\n        DepthTool,\n        typer.Option(\n            \"--depth-tool\", help=\"Tool for depth analysis\"\n        ),\n    ] = DepthTool.MOSDEPTH,\n    require_pass: Annotated[\n        bool,\n        typer.Option(\n            \"--require-pass\", help=\"Only consider variants that pass caller filters\"\n        ),\n    ] = False,\n    min_bracken_frac: Annotated[\n        float,\n        typer.Option(\n            \"--min-bracken-frac\", help=\"Minimum Bracken abundance fraction\"\n        ),\n    ] = 0.70,\n    min_bracken_reads: Annotated[\n        int,\n        typer.Option(\n            \"--min-bracken-reads\", help=\"Minimum Bracken read count\"\n        ),\n    ] = 100000,\n    ref_dir: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"--ref-dir\", help=\"Admin reference directory\"\n        ),\n    ] = None,\n    on_fail: Annotated[\n        str,\n        typer.Option(\n            \"--on-fail\", help=\"Action when reference resolution fails\"\n        ),\n    ] = \"error\",\n    emit_vcf: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-vcf\", help=\"Emit VCF file with ambiguous sites\"\n        ),\n    ] = False,\n    emit_bed: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-bed\", help=\"Emit BED file with ambiguous sites\"\n        ),\n    ] = False,\n    emit_matrix: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-matrix\", help=\"Emit variant matrix in TSV format\"\n        ),\n    ] = False,\n    emit_per_contig: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-per-contig\", help=\"Emit per-contig summary statistics\"\n        ),\n    ] = False,\n    emit_multiqc: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-multiqc\", help=\"Emit MultiQC-compatible metrics\"\n        ),\n    ] = False,\n    emit_provenance: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-provenance\", help=\"Emit JSON provenance file\"\n        ),\n    ] = False,\n    tsv_mode: Annotated[\n        TSVMode,\n        typer.Option(\n            \"--tsv-mode\", help=\"TSV output mode\"\n        ),\n    ] = TSVMode.OVERWRITE,\n    stdout: Annotated[\n        bool,\n        typer.Option(\n            \"--stdout\", help=\"Write summary to stdout instead of file\"\n        ),\n    ] = False,\n) -&gt; None:\n    \"\"\"\n    Reference-mapping mode: map reads to a reference genome.\n\n    Maps paired-end reads to a reference genome to identify ambiguous sites.\n    Reference can be provided directly, looked up by species, or selected from Bracken.\n    \"\"\"\n    try:\n        # Validate emit flags with stdout\n        if stdout and any([emit_vcf, emit_bed, emit_matrix, emit_per_contig, emit_multiqc, emit_provenance]):\n            console.print(\"[red]Error: --stdout cannot be used with --emit-* flags[/red]\")\n            raise typer.Exit(1)\n\n        # Get global options from context\n        dry_run = ctx.parent.params.get(\"dry_run\", False) if ctx.parent else False\n\n        # Create execution plan\n        plan = create_run_plan(\n            mode=Mode.REF,\n            r1=r1,\n            r2=r2,\n            reference=reference,\n            sample=sample,\n            output_dir=output_dir,\n            threads=threads,\n            mapper=mapper,\n            caller=caller,\n            bbtools_mem=bbtools_mem,\n            dp_min=dp_min,\n            maf_min=maf_min,\n            dp_cap=dp_cap,\n            mapq=mapq,\n            depth_tool=depth_tool.value,\n            require_pass=require_pass,\n            dry_run=dry_run,\n            to_stdout=stdout,\n            emit_vcf=emit_vcf,\n            emit_bed=emit_bed,\n            emit_matrix=emit_matrix,\n            emit_per_contig=emit_per_contig,\n            emit_multiqc=emit_multiqc,\n            emit_provenance=emit_provenance,\n            species=species,\n            bracken=bracken,\n            ref_dir=ref_dir,\n            on_fail=on_fail,\n            tsv_mode=tsv_mode,\n            min_bracken_frac=min_bracken_frac,\n            min_bracken_reads=min_bracken_reads,\n        )\n\n        # Execute plan\n        result, provenance_record = execute_plan(plan, \n                            species=species, \n                            bracken=bracken, \n                            ref_dir=ref_dir, \n                            on_fail=on_fail,\n                            min_bracken_frac=min_bracken_frac,\n                            min_bracken_reads=min_bracken_reads)\n\n        # If this was a dry run, we're done\n        if dry_run:\n            return\n\n        # Handle provenance output\n        if emit_provenance and provenance_record:\n            from .provenance import write_provenance_json\n            out_dir = output_dir or Path.cwd()\n            provenance_path = out_dir / \"run_provenance.json\"\n            write_provenance_json([provenance_record], provenance_path)\n            console.print(f\"Provenance written to {provenance_path}\")\n\n        if not stdout:\n            console.print(f\"[green]Reference-mapping completed for sample {result.sample}[/green]\")\n            total_sites = result.ambiguous_snv_count + result.ambiguous_indel_count + result.ambiguous_del_count\n            console.print(f\"Found {total_sites} ambiguous sites\")\n\n    except Exception as e:\n        handle_exception_with_exit(e, \"Reference-mapping mode failed\")\n</code></pre>"},{"location":"reference/#ssiamb.cli.self","title":"<code>self(ctx, r1, r2, assembly, sample=None, output_dir=None, threads=4, mapper='minimap2', caller='bbtools', bbtools_mem=None, dp_min=10, maf_min=0.1, mapq=30, dp_cap=100, depth_tool=DepthTool.MOSDEPTH, require_pass=False, emit_vcf=False, emit_bed=False, emit_matrix=False, emit_per_contig=False, emit_multiqc=False, emit_provenance=False, tsv_mode=TSVMode.OVERWRITE, stdout=False)</code>","text":"<p>Self-mapping mode: map reads to their own assembly.</p> <p>Maps paired-end reads to the provided assembly to identify ambiguous sites where the assembly may not represent the true sequence.</p> Source code in <code>src/ssiamb/cli.py</code> <pre><code>@app.command()\ndef self(\n    ctx: typer.Context,\n    r1: Annotated[\n        Path,\n        typer.Option(\n            \"--r1\", help=\"Forward reads (FASTQ, can be gzipped)\"\n        ),\n    ],\n    r2: Annotated[\n        Path,\n        typer.Option(\n            \"--r2\", help=\"Reverse reads (FASTQ, can be gzipped)\"\n        ),\n    ],\n    assembly: Annotated[\n        Path,\n        typer.Option(\n            \"--assembly\", help=\"Assembly FASTA file\"\n        ),\n    ],\n    sample: Annotated[\n        Optional[str],\n        typer.Option(\n            \"--sample\", help=\"Sample name (inferred from filenames if not provided)\"\n        ),\n    ] = None,\n    output_dir: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"--outdir\", \"-o\", help=\"Output directory (default: current)\"\n        ),\n    ] = None,\n    threads: Annotated[\n        int,\n        typer.Option(\n            \"--threads\", \"-t\", help=\"Number of threads\"\n        ),\n    ] = 4,\n    mapper: Annotated[\n        str,\n        typer.Option(\n            \"--mapper\", help=\"Mapper to use\"\n        ),\n    ] = \"minimap2\",\n    caller: Annotated[\n        str,\n        typer.Option(\n            \"--caller\", help=\"Variant caller to use\"\n        ),\n    ] = \"bbtools\",\n    bbtools_mem: Annotated[\n        Optional[str],\n        typer.Option(\n            \"--bbtools-mem\", help=\"BBTools heap memory (e.g., '4g', '8g')\"\n        ),\n    ] = None,\n    dp_min: Annotated[\n        int,\n        typer.Option(\n            \"--dp-min\", help=\"Minimum depth for ambiguous sites\"\n        ),\n    ] = 10,\n    maf_min: Annotated[\n        float,\n        typer.Option(\n            \"--maf-min\", help=\"Minimum minor allele frequency\"\n        ),\n    ] = 0.1,\n    mapq: Annotated[\n        int,\n        typer.Option(\n            \"--mapq\", help=\"Minimum mapping quality for depth analysis\"\n        ),\n    ] = 30,\n    dp_cap: Annotated[\n        int,\n        typer.Option(\n            \"--dp-cap\", help=\"Maximum depth cap for variant analysis\"\n        ),\n    ] = 100,\n    depth_tool: Annotated[\n        DepthTool,\n        typer.Option(\n            \"--depth-tool\", help=\"Tool for depth analysis\"\n        ),\n    ] = DepthTool.MOSDEPTH,\n    require_pass: Annotated[\n        bool,\n        typer.Option(\n            \"--require-pass\", help=\"Only consider variants that pass caller filters\"\n        ),\n    ] = False,\n    emit_vcf: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-vcf\", help=\"Emit VCF file with ambiguous sites\"\n        ),\n    ] = False,\n    emit_bed: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-bed\", help=\"Emit BED file with ambiguous sites\"\n        ),\n    ] = False,\n    emit_matrix: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-matrix\", help=\"Emit variant matrix in TSV format\"\n        ),\n    ] = False,\n    emit_per_contig: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-per-contig\", help=\"Emit per-contig summary statistics\"\n        ),\n    ] = False,\n    emit_multiqc: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-multiqc\", help=\"Emit MultiQC-compatible metrics\"\n        ),\n    ] = False,\n    emit_provenance: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-provenance\", help=\"Emit JSON provenance file\"\n        ),\n    ] = False,\n    tsv_mode: Annotated[\n        TSVMode,\n        typer.Option(\n            \"--tsv-mode\", help=\"TSV output mode\"\n        ),\n    ] = TSVMode.OVERWRITE,\n    stdout: Annotated[\n        bool,\n        typer.Option(\n            \"--stdout\", help=\"Write summary to stdout instead of file\"\n        ),\n    ] = False,\n) -&gt; None:\n    \"\"\"\n    Self-mapping mode: map reads to their own assembly.\n\n    Maps paired-end reads to the provided assembly to identify ambiguous sites\n    where the assembly may not represent the true sequence.\n    \"\"\"\n    try:\n        # Validate emit flags with stdout\n        if stdout and any([emit_vcf, emit_bed, emit_matrix, emit_per_contig, emit_multiqc, emit_provenance]):\n            console.print(\"[red]Error: --stdout cannot be used with --emit-* flags[/red]\")\n            raise typer.Exit(1)\n\n        # Get global options from context\n        dry_run = ctx.parent.params.get(\"dry_run\", False) if ctx.parent else False\n\n        # Create execution plan\n        plan = create_run_plan(\n            mode=Mode.SELF,\n            r1=r1,\n            r2=r2,\n            assembly=assembly,\n            sample=sample,\n            output_dir=output_dir,\n            threads=threads,\n            mapper=mapper,\n            caller=caller,\n            bbtools_mem=bbtools_mem,\n            dp_min=dp_min,\n            maf_min=maf_min,\n            dp_cap=dp_cap,\n            mapq=mapq,\n            depth_tool=depth_tool.value,\n            require_pass=require_pass,\n            dry_run=dry_run,\n            to_stdout=stdout,\n            emit_vcf=emit_vcf,\n            emit_bed=emit_bed,\n            emit_matrix=emit_matrix,\n            emit_per_contig=emit_per_contig,\n            emit_multiqc=emit_multiqc,\n            emit_provenance=emit_provenance,\n            tsv_mode=tsv_mode,\n        )\n\n        # Execute plan\n        result, provenance_record = execute_plan(plan)\n\n        # If this was a dry run, we're done\n        if dry_run:\n            return\n\n        # Handle provenance output\n        if emit_provenance and provenance_record:\n            from .provenance import write_provenance_json\n            out_dir = output_dir or Path.cwd()\n            provenance_path = out_dir / \"run_provenance.json\"\n            write_provenance_json([provenance_record], provenance_path)\n            console.print(f\"Provenance written to {provenance_path}\")\n\n        if not stdout:\n            console.print(f\"[green]Self-mapping completed for sample {result.sample}[/green]\")\n            total_sites = result.ambiguous_snv_count + result.ambiguous_indel_count + result.ambiguous_del_count\n            console.print(f\"Found {total_sites} ambiguous sites\")\n\n    except Exception as e:\n        handle_exception_with_exit(e, \"Self-mapping mode failed\")\n</code></pre>"},{"location":"reference/#ssiamb.cli.summarize","title":"<code>summarize(ctx, vcf, bam, output=None, dp_min=10, maf_min=0.1, dp_cap=100, require_pass=False, emit_vcf=False, emit_bed=False, emit_matrix=False, emit_per_contig=False, emit_multiqc=False, emit_provenance=False, mode='combined', stdout=False)</code>","text":"<p>Summarize VCF and BAM files to generate ambiguous site summary.</p> <p>Analyzes a VCF file with BAM for denominator calculation to produce ambiguous site statistics.</p> Source code in <code>src/ssiamb/cli.py</code> <pre><code>@app.command()\ndef summarize(\n    ctx: typer.Context,\n    vcf: Annotated[\n        Path,\n        typer.Option(\n            \"--vcf\", help=\"VCF file to summarize\"\n        ),\n    ],\n    bam: Annotated[\n        Path,\n        typer.Option(\n            \"--bam\", help=\"BAM file for denominator calculation\"\n        ),\n    ],\n    output: Annotated[\n        Optional[Path],\n        typer.Option(\n            \"--output\", \"-o\", help=\"Output summary file\"\n        ),\n    ] = None,\n    dp_min: Annotated[\n        int,\n        typer.Option(\n            \"--dp-min\", help=\"Minimum depth for ambiguous sites\"\n        ),\n    ] = 10,\n    maf_min: Annotated[\n        float,\n        typer.Option(\n            \"--maf-min\", help=\"Minimum minor allele frequency\"\n        ),\n    ] = 0.1,\n    dp_cap: Annotated[\n        int,\n        typer.Option(\n            \"--dp-cap\", help=\"Maximum depth cap for variant analysis\"\n        ),\n    ] = 100,\n    require_pass: Annotated[\n        bool,\n        typer.Option(\n            \"--require-pass\", help=\"Only consider variants that pass caller filters\"\n        ),\n    ] = False,\n    emit_vcf: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-vcf\", help=\"Emit VCF file with ambiguous sites\"\n        ),\n    ] = False,\n    emit_bed: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-bed\", help=\"Emit BED file with ambiguous sites\"\n        ),\n    ] = False,\n    emit_matrix: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-matrix\", help=\"Emit variant matrix in TSV format\"\n        ),\n    ] = False,\n    emit_per_contig: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-per-contig\", help=\"Emit per-contig summary statistics\"\n        ),\n    ] = False,\n    emit_multiqc: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-multiqc\", help=\"Emit MultiQC-compatible metrics\"\n        ),\n    ] = False,\n    emit_provenance: Annotated[\n        bool,\n        typer.Option(\n            \"--emit-provenance\", help=\"Emit JSON provenance file\"\n        ),\n    ] = False,\n    mode: Annotated[\n        str,\n        typer.Option(\n            \"--mode\", help=\"Summary mode\"\n        ),\n    ] = \"combined\",\n    stdout: Annotated[\n        bool,\n        typer.Option(\n            \"--stdout\", help=\"Write summary to stdout instead of file\"\n        ),\n    ] = False,\n) -&gt; None:\n    \"\"\"\n    Summarize VCF and BAM files to generate ambiguous site summary.\n\n    Analyzes a VCF file with BAM for denominator calculation to produce\n    ambiguous site statistics.\n    \"\"\"\n    try:\n        # Get global options from context\n        dry_run = ctx.parent.params.get(\"dry_run\", False) if ctx.parent else False\n\n        if dry_run:\n            console.print(\"[yellow]DRY RUN - Summarize mode plan:[/yellow]\")\n            console.print(f\"  [bold]Input validation:[/bold]\")\n            console.print(f\"    VCF file: {vcf} {'\u2713' if vcf.exists() else '\u2717 (missing)'}\")\n            console.print(f\"    BAM file: {bam} {'\u2713' if bam.exists() else '\u2717 (missing)'}\")\n            console.print(f\"  [bold]Sample name:[/bold] {vcf.stem.split('.')[0] if vcf.exists() else 'unknown'}\")\n            console.print(f\"  [bold]Analysis plan:[/bold]\")\n            console.print(f\"    1. Run mosdepth on BAM (MAPQ\u226530, depth\u226510, exclude duplicates)\")\n            console.print(f\"    2. Parse VCF for ambiguous sites\")\n            console.print(f\"    3. Count SNVs: dp_min={dp_min}, maf_min={maf_min}, dp_cap={dp_cap}\")\n            console.print(f\"    4. Count indels and deletions for secondary metrics\")\n            console.print(f\"    5. Calculate mapping rate from BAM\")\n            console.print(f\"  [bold]Outputs planned:[/bold]\")\n            if stdout:\n                console.print(f\"    Summary: stdout\")\n            else:\n                console.print(f\"    Summary: {output or 'ambiguous_summary.tsv'}\")\n            if emit_vcf:\n                console.print(f\"    VCF: {vcf.stem}.ambiguous_sites.vcf.gz\")\n            if emit_bed:\n                console.print(f\"    BED: {vcf.stem}.ambiguous_sites.bed.gz\")\n            if emit_matrix:\n                console.print(f\"    Matrix: {vcf.stem}.variant_matrix.tsv.gz\")\n            if emit_per_contig:\n                console.print(f\"    Per-contig: {vcf.stem}.per_contig_summary.tsv\")\n            if emit_multiqc:\n                console.print(f\"    MultiQC: {vcf.stem}.multiqc.tsv\")\n            if emit_provenance:\n                console.print(f\"    Provenance: run_provenance.json\")\n            console.print(f\"  [bold]Filters:[/bold] {'PASS-only' if require_pass else 'All variants'}\")\n            console.print(\"[green]Dry run completed - no files written[/green]\")\n            return\n\n        console.print(\"[green]Running summarize mode...[/green]\")\n        console.print(f\"VCF file: {vcf}\")\n        console.print(f\"BAM file: {bam}\")\n        console.print(f\"Output: {output or 'stdout' if stdout else 'auto'}\")\n        console.print(f\"Mode: {mode}\")\n        console.print(f\"Thresholds: dp_min={dp_min}, maf_min={maf_min}\")\n\n        # Call the summarize logic\n        results = run_summarize(\n            vcf=vcf,\n            bam=bam,\n            output=output,\n            dp_min=dp_min,\n            maf_min=maf_min,\n            dp_cap=dp_cap,\n            require_pass=require_pass,\n            emit_vcf=emit_vcf,\n            emit_bed=emit_bed,\n            emit_matrix=emit_matrix,\n            emit_per_contig=emit_per_contig,\n            emit_multiqc=emit_multiqc,\n            emit_provenance=emit_provenance,\n            to_stdout=stdout,\n        )\n\n        if not stdout:\n            console.print(f\"[green]Summarize completed with {len(results)} results[/green]\")\n\n    except Exception as e:\n        handle_exception_with_exit(e, \"Summarize mode failed\")\n</code></pre>"},{"location":"reference/#ssiamb.cli.version_callback","title":"<code>version_callback(value)</code>","text":"<p>Print version and exit.</p> Source code in <code>src/ssiamb/cli.py</code> <pre><code>def version_callback(value: bool) -&gt; None:\n    \"\"\"Print version and exit.\"\"\"\n    if value:\n        console.print(f\"ssiamb version {__version__}\")\n        raise typer.Exit()\n</code></pre>"},{"location":"reference/#configuration","title":"Configuration","text":"<p>Configuration management for ssiamb.</p> <p>This module handles loading and merging configuration from: 1. Built-in defaults (config/defaults.yaml) 2. User-specified config files (--config) 3. Environment variables 4. Command-line overrides</p>"},{"location":"reference/#ssiamb.config.SsiambConfig","title":"<code>SsiambConfig(thresholds, species_aliases, tools, output)</code>  <code>dataclass</code>","text":"<p>Complete ssiamb configuration.</p> <p>This holds all configurable values that were previously hardcoded, allowing users to customize behavior via config files.</p>"},{"location":"reference/#ssiamb.config.SsiambConfig.get_output_setting","title":"<code>get_output_setting(key, default=None)</code>","text":"<p>Get an output formatting setting.</p> Source code in <code>src/ssiamb/config.py</code> <pre><code>def get_output_setting(self, key: str, default: Any = None) -&gt; Any:\n    \"\"\"Get an output formatting setting.\"\"\"\n    return self.output.get(key, default)\n</code></pre>"},{"location":"reference/#ssiamb.config.SsiambConfig.get_species_alias","title":"<code>get_species_alias(species)</code>","text":"<p>Get species alias, returning original name if no alias exists.</p> Source code in <code>src/ssiamb/config.py</code> <pre><code>def get_species_alias(self, species: str) -&gt; str:\n    \"\"\"Get species alias, returning original name if no alias exists.\"\"\"\n    return self.species_aliases.get(species, species)\n</code></pre>"},{"location":"reference/#ssiamb.config.SsiambConfig.get_threshold","title":"<code>get_threshold(key, default=None)</code>","text":"<p>Get a threshold value with fallback.</p> Source code in <code>src/ssiamb/config.py</code> <pre><code>def get_threshold(self, key: str, default: Any = None) -&gt; Any:\n    \"\"\"Get a threshold value with fallback.\"\"\"\n    return self.thresholds.get(key, default)\n</code></pre>"},{"location":"reference/#ssiamb.config.SsiambConfig.get_tool_setting","title":"<code>get_tool_setting(tool, key, default=None)</code>","text":"<p>Get a tool-specific setting.</p> Source code in <code>src/ssiamb/config.py</code> <pre><code>def get_tool_setting(self, tool: str, key: str, default: Any = None) -&gt; Any:\n    \"\"\"Get a tool-specific setting.\"\"\"\n    return self.tools.get(tool, {}).get(key, default)\n</code></pre>"},{"location":"reference/#ssiamb.config.SsiambConfig.load","title":"<code>load(config_path=None)</code>  <code>classmethod</code>","text":"<p>Load configuration from files and environment.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>Optional[Path]</code> <p>Optional path to user config file</p> <code>None</code> <p>Returns:</p> Type Description <code>SsiambConfig</code> <p>Merged configuration object</p> Source code in <code>src/ssiamb/config.py</code> <pre><code>@classmethod\ndef load(cls, config_path: Optional[Path] = None) -&gt; SsiambConfig:\n    \"\"\"\n    Load configuration from files and environment.\n\n    Args:\n        config_path: Optional path to user config file\n\n    Returns:\n        Merged configuration object\n    \"\"\"\n    # Start with built-in defaults\n    config = cls._load_defaults()\n\n    # Overlay user config if provided\n    if config_path and config_path.exists():\n        user_config = cls._load_yaml(config_path)\n        config = cls._merge_configs(config, user_config)\n\n    # Apply environment variable overrides\n    config = cls._apply_env_overrides(config)\n\n    # Normalize species alias keys for consistent lookup\n    if \"species_aliases\" in config:\n        config[\"species_aliases\"] = cls._normalize_species_aliases(config[\"species_aliases\"])\n\n    return cls(\n        thresholds=config.get(\"thresholds\", {}),\n        species_aliases=config.get(\"species_aliases\", {}),\n        tools=config.get(\"tools\", {}),\n        output=config.get(\"output\", {})\n    )\n</code></pre>"},{"location":"reference/#ssiamb.config.get_config","title":"<code>get_config()</code>","text":"<p>Get the global configuration instance.</p> Source code in <code>src/ssiamb/config.py</code> <pre><code>def get_config() -&gt; SsiambConfig:\n    \"\"\"Get the global configuration instance.\"\"\"\n    global _config\n    if _config is None:\n        _config = SsiambConfig.load()\n    return _config\n</code></pre>"},{"location":"reference/#ssiamb.config.load_config","title":"<code>load_config(config_path=None)</code>","text":"<p>Load and set configuration from file.</p> Source code in <code>src/ssiamb/config.py</code> <pre><code>def load_config(config_path: Optional[Path] = None) -&gt; SsiambConfig:\n    \"\"\"Load and set configuration from file.\"\"\"\n    config = SsiambConfig.load(config_path)\n    set_config(config)\n    return config\n</code></pre>"},{"location":"reference/#ssiamb.config.set_config","title":"<code>set_config(config)</code>","text":"<p>Set the global configuration instance.</p> Source code in <code>src/ssiamb/config.py</code> <pre><code>def set_config(config: SsiambConfig) -&gt; None:\n    \"\"\"Set the global configuration instance.\"\"\"\n    global _config\n    _config = config\n</code></pre>"},{"location":"reference/#mapping","title":"Mapping","text":"<p>Mapping and index handling for minimap2 and bwa-mem2.</p> <p>This module provides functionality for: - Building and managing indexes for reference sequences - Mapping paired-end FASTQ files to references - Generating sorted BAM files with proper read groups</p>"},{"location":"reference/#ssiamb.mapping.ExternalToolError","title":"<code>ExternalToolError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when external tools are missing or fail.</p>"},{"location":"reference/#ssiamb.mapping.MappingError","title":"<code>MappingError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when mapping operations fail.</p>"},{"location":"reference/#ssiamb.mapping.calculate_mapping_rate","title":"<code>calculate_mapping_rate(bam_path)</code>","text":"<p>Calculate mapping rate from BAM file using samtools stats.</p> <p>Parameters:</p> Name Type Description Default <code>bam_path</code> <code>Path</code> <p>Path to sorted BAM file</p> required <p>Returns:</p> Type Description <code>float</code> <p>Mapping rate as fraction (0.0-1.0)</p> <p>Raises:</p> Type Description <code>MappingError</code> <p>If BAM file doesn't exist or samtools fails</p> <code>ExternalToolError</code> <p>If samtools is not available</p> Source code in <code>src/ssiamb/mapping.py</code> <pre><code>def calculate_mapping_rate(bam_path: Path) -&gt; float:\n    \"\"\"\n    Calculate mapping rate from BAM file using samtools stats.\n\n    Args:\n        bam_path: Path to sorted BAM file\n\n    Returns:\n        Mapping rate as fraction (0.0-1.0)\n\n    Raises:\n        MappingError: If BAM file doesn't exist or samtools fails\n        ExternalToolError: If samtools is not available\n    \"\"\"\n    if not shutil.which(\"samtools\"):\n        raise ExternalToolError(\"samtools not found in PATH\")\n\n    if not bam_path.exists():\n        raise MappingError(f\"BAM file not found: {bam_path}\")\n\n    logger.debug(f\"Calculating mapping rate for {bam_path}\")\n\n    try:\n        # Run samtools stats to get read counts\n        cmd = [\"samtools\", \"stats\", str(bam_path)]\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True\n        )\n\n        total_reads = 0\n        mapped_reads = 0\n\n        # Parse samtools stats output\n        for line in result.stdout.splitlines():\n            if line.startswith(\"SN\\t\"):\n                parts = line.split(\"\\t\")\n                if len(parts) &gt;= 3:\n                    metric = parts[1]\n                    value_str = parts[2].strip()\n\n                    # Extract numbers (some lines have additional text after the number)\n                    try:\n                        value = int(value_str.split()[0])\n                    except (ValueError, IndexError):\n                        continue\n\n                    if \"raw total sequences:\" in metric:\n                        total_reads = value\n                    elif \"reads mapped:\" in metric:\n                        mapped_reads = value\n\n        if total_reads == 0:\n            logger.warning(f\"No reads found in BAM file {bam_path}\")\n            return 0.0\n\n        mapping_rate = mapped_reads / total_reads\n        logger.debug(f\"Mapping rate: {mapped_reads}/{total_reads} = {mapping_rate:.4f}\")\n\n        return mapping_rate\n\n    except subprocess.CalledProcessError as e:\n        raise MappingError(f\"samtools stats failed: {e.stderr}\")\n    except Exception as e:\n        raise MappingError(f\"Failed to calculate mapping rate: {e}\")\n</code></pre>"},{"location":"reference/#ssiamb.mapping.check_external_tools","title":"<code>check_external_tools()</code>","text":"<p>Check availability and versions of external mapping tools.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, str]]</code> <p>Dictionary mapping tool names to availability and version info.</p> <code>Dict[str, Dict[str, str]]</code> <p>Each tool entry contains:</p> <code>Dict[str, Dict[str, str]]</code> <ul> <li>'available': boolean status</li> </ul> <code>Dict[str, Dict[str, str]]</code> <ul> <li>'version': version string if available, or error message</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tools = check_external_tools()\n&gt;&gt;&gt; if not tools['minimap2']['available']:\n...     raise ExternalToolError(\"minimap2 not found\")\n&gt;&gt;&gt; print(f\"minimap2 version: {tools['minimap2']['version']}\")\n</code></pre> Source code in <code>src/ssiamb/mapping.py</code> <pre><code>def check_external_tools() -&gt; Dict[str, Dict[str, str]]:\n    \"\"\"\n    Check availability and versions of external mapping tools.\n\n    Returns:\n        Dictionary mapping tool names to availability and version info.\n        Each tool entry contains:\n        - 'available': boolean status\n        - 'version': version string if available, or error message\n\n    Examples:\n        &gt;&gt;&gt; tools = check_external_tools()\n        &gt;&gt;&gt; if not tools['minimap2']['available']:\n        ...     raise ExternalToolError(\"minimap2 not found\")\n        &gt;&gt;&gt; print(f\"minimap2 version: {tools['minimap2']['version']}\")\n    \"\"\"\n    tools = {}\n\n    # Define tools and their version commands\n    tool_commands = {\n        'minimap2': ['minimap2', '--version'],\n        'bwa-mem2': ['bwa-mem2', 'version'],\n        'samtools': ['samtools', '--version']\n    }\n\n    for tool, version_cmd in tool_commands.items():\n        tools[tool] = {'available': False, 'version': 'unknown'}\n\n        # Check if tool is in PATH\n        if shutil.which(tool) is None:\n            tools[tool]['version'] = 'not found in PATH'\n            logger.debug(f\"Tool {tool}: not found\")\n            continue\n\n        # Try to get version\n        try:\n            result = subprocess.run(\n                version_cmd,\n                capture_output=True,\n                text=True,\n                timeout=5  # Prevent hanging\n            )\n            if result.returncode == 0:\n                tools[tool]['available'] = True\n                # Extract version from output (first line typically)\n                version_line = result.stdout.strip().split('\\n')[0] if result.stdout else 'version check succeeded'\n                tools[tool]['version'] = version_line\n                logger.debug(f\"Tool {tool}: available, version: {version_line}\")\n            else:\n                tools[tool]['version'] = f'version check failed (exit {result.returncode})'\n                logger.debug(f\"Tool {tool}: found but version check failed\")\n        except subprocess.TimeoutExpired:\n            tools[tool]['version'] = 'version check timed out'\n            logger.debug(f\"Tool {tool}: found but version check timed out\")\n        except Exception as e:\n            tools[tool]['version'] = f'version check error: {e}'\n            logger.debug(f\"Tool {tool}: found but version check error: {e}\")\n\n    return tools\n</code></pre>"},{"location":"reference/#ssiamb.mapping.ensure_indexes_self","title":"<code>ensure_indexes_self(fasta_path, mapper)</code>","text":"<p>Ensure index files exist for self-mode mapping, building them if missing.</p> <p>This function builds index files next to the FASTA file if they don't exist. For minimap2, creates .mmi file. For bwa-mem2, creates .0123, .amb, .ann,  .pac, .bwt.2bit.64 files.</p> <p>Parameters:</p> Name Type Description Default <code>fasta_path</code> <code>Path</code> <p>Path to reference FASTA file</p> required <code>mapper</code> <code>Mapper</code> <p>Mapper type (minimap2 or bwa-mem2)</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If FASTA file doesn't exist</p> <code>ExternalToolError</code> <p>If required mapper tool is not available</p> <code>MappingError</code> <p>If index building fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ensure_indexes_self(Path(\"ref.fasta\"), Mapper.MINIMAP2)\n# Creates ref.mmi if it doesn't exist\n</code></pre> Source code in <code>src/ssiamb/mapping.py</code> <pre><code>def ensure_indexes_self(fasta_path: Path, mapper: Mapper) -&gt; None:\n    \"\"\"\n    Ensure index files exist for self-mode mapping, building them if missing.\n\n    This function builds index files next to the FASTA file if they don't exist.\n    For minimap2, creates .mmi file. For bwa-mem2, creates .0123, .amb, .ann, \n    .pac, .bwt.2bit.64 files.\n\n    Args:\n        fasta_path: Path to reference FASTA file\n        mapper: Mapper type (minimap2 or bwa-mem2)\n\n    Raises:\n        FileNotFoundError: If FASTA file doesn't exist\n        ExternalToolError: If required mapper tool is not available\n        MappingError: If index building fails\n\n    Examples:\n        &gt;&gt;&gt; ensure_indexes_self(Path(\"ref.fasta\"), Mapper.MINIMAP2)\n        # Creates ref.mmi if it doesn't exist\n    \"\"\"\n    if not fasta_path.exists():\n        raise FileNotFoundError(f\"Reference FASTA not found: {fasta_path}\")\n\n    # Check if indexes already exist\n    if indexes_exist(fasta_path, mapper):\n        logger.info(f\"Index files already exist for {fasta_path} ({mapper.value})\")\n        return\n\n    # Check tool availability\n    tools = check_external_tools()\n    tool_name = mapper.value  # Use the actual tool name without modification\n    if not tools.get(tool_name, {}).get('available', False):\n        version_info = tools.get(tool_name, {}).get('version', 'unknown')\n        raise ExternalToolError(f\"{tool_name} not available: {version_info}\")\n\n    logger.info(f\"Building {mapper.value} index for {fasta_path}\")\n\n    try:\n        if mapper == Mapper.MINIMAP2:\n            _build_minimap2_index(fasta_path)\n        elif mapper == Mapper.BWA_MEM2:\n            _build_bwa_mem2_index(fasta_path)\n        else:\n            raise ValueError(f\"Unsupported mapper: {mapper}\")\n\n    except subprocess.CalledProcessError as e:\n        raise MappingError(f\"Failed to build {mapper.value} index: {e}\")\n</code></pre>"},{"location":"reference/#ssiamb.mapping.get_index_files","title":"<code>get_index_files(fasta_path, mapper)</code>","text":"<p>Get expected index file paths for a given FASTA and mapper.</p> <p>Parameters:</p> Name Type Description Default <code>fasta_path</code> <code>Path</code> <p>Path to reference FASTA file</p> required <code>mapper</code> <code>Mapper</code> <p>Mapper type (minimap2 or bwa-mem2)</p> required <p>Returns:</p> Type Description <code>List[Path]</code> <p>List of expected index file paths</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If mapper is not supported</p> Source code in <code>src/ssiamb/mapping.py</code> <pre><code>def get_index_files(fasta_path: Path, mapper: Mapper) -&gt; List[Path]:\n    \"\"\"\n    Get expected index file paths for a given FASTA and mapper.\n\n    Args:\n        fasta_path: Path to reference FASTA file\n        mapper: Mapper type (minimap2 or bwa-mem2)\n\n    Returns:\n        List of expected index file paths\n\n    Raises:\n        ValueError: If mapper is not supported\n    \"\"\"\n    if mapper == Mapper.MINIMAP2:\n        return [fasta_path.with_suffix('.mmi')]\n\n    elif mapper == Mapper.BWA_MEM2:\n        # BWA-MEM2 creates index files with the original filename plus extensions\n        extensions = ['.0123', '.amb', '.ann', '.pac', '.bwt.2bit.64']\n        return [Path(str(fasta_path) + ext) for ext in extensions]\n\n    else:\n        raise ValueError(f\"Unsupported mapper: {mapper}\")\n</code></pre>"},{"location":"reference/#ssiamb.mapping.index_bam","title":"<code>index_bam(bam_path)</code>","text":"<p>Index a BAM file using samtools.</p> <p>Parameters:</p> Name Type Description Default <code>bam_path</code> <code>Path</code> <p>Path to BAM file to index</p> required <p>Raises:</p> Type Description <code>MappingError</code> <p>If indexing fails</p> Source code in <code>src/ssiamb/mapping.py</code> <pre><code>def index_bam(bam_path: Path) -&gt; None:\n    \"\"\"\n    Index a BAM file using samtools.\n\n    Args:\n        bam_path: Path to BAM file to index\n\n    Raises:\n        MappingError: If indexing fails\n    \"\"\"\n    if not bam_path.exists():\n        raise MappingError(f\"BAM file not found: {bam_path}\")\n\n    index_path = bam_path.with_suffix('.bam.bai')\n\n    logger.debug(f\"Indexing BAM file: {bam_path}\")\n\n    try:\n        cmd = [\"samtools\", \"index\", str(bam_path)]\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True\n        )\n\n        if not index_path.exists():\n            raise MappingError(f\"BAM index was not created: {index_path}\")\n\n        logger.debug(f\"Created BAM index: {index_path}\")\n\n    except subprocess.CalledProcessError as e:\n        raise MappingError(f\"Failed to index BAM {bam_path}: {e.stderr}\")\n</code></pre>"},{"location":"reference/#ssiamb.mapping.indexes_exist","title":"<code>indexes_exist(fasta_path, mapper)</code>","text":"<p>Check if all required index files exist for a given FASTA and mapper.</p> <p>Parameters:</p> Name Type Description Default <code>fasta_path</code> <code>Path</code> <p>Path to reference FASTA file</p> required <code>mapper</code> <code>Mapper</code> <p>Mapper type</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all index files exist, False otherwise</p> Source code in <code>src/ssiamb/mapping.py</code> <pre><code>def indexes_exist(fasta_path: Path, mapper: Mapper) -&gt; bool:\n    \"\"\"\n    Check if all required index files exist for a given FASTA and mapper.\n\n    Args:\n        fasta_path: Path to reference FASTA file\n        mapper: Mapper type\n\n    Returns:\n        True if all index files exist, False otherwise\n    \"\"\"\n    index_files = get_index_files(fasta_path, mapper)\n    return all(idx_file.exists() for idx_file in index_files)\n</code></pre>"},{"location":"reference/#ssiamb.mapping.map_fastqs","title":"<code>map_fastqs(mapper, fasta_path, r1_path, r2_path, sample_name, threads=4, output_path=None)</code>","text":"<p>Map paired-end FASTQ files to reference and return sorted BAM.</p> <p>Parameters:</p> Name Type Description Default <code>mapper</code> <code>Mapper</code> <p>Mapper type (minimap2 or bwa-mem2)</p> required <code>fasta_path</code> <code>Path</code> <p>Path to reference FASTA file</p> required <code>r1_path</code> <code>Path</code> <p>Path to R1 FASTQ file</p> required <code>r2_path</code> <code>Path</code> <p>Path to R2 FASTQ file  </p> required <code>sample_name</code> <code>str</code> <p>Sample name for read group</p> required <code>threads</code> <code>int</code> <p>Number of threads to use</p> <code>4</code> <code>output_path</code> <code>Optional[Path]</code> <p>Output BAM path (auto-generated if None)</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to sorted BAM file</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If input files don't exist</p> <code>ExternalToolError</code> <p>If required tools are not available</p> <code>MappingError</code> <p>If mapping fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bam_path = map_fastqs(\n...     Mapper.MINIMAP2,\n...     Path(\"ref.fasta\"),\n...     Path(\"sample_R1.fastq.gz\"),\n...     Path(\"sample_R2.fastq.gz\"),\n...     \"sample123\"\n... )\n</code></pre> Source code in <code>src/ssiamb/mapping.py</code> <pre><code>def map_fastqs(\n    mapper: Mapper,\n    fasta_path: Path,\n    r1_path: Path,\n    r2_path: Path,\n    sample_name: str,\n    threads: int = 4,\n    output_path: Optional[Path] = None\n) -&gt; Path:\n    \"\"\"\n    Map paired-end FASTQ files to reference and return sorted BAM.\n\n    Args:\n        mapper: Mapper type (minimap2 or bwa-mem2)\n        fasta_path: Path to reference FASTA file\n        r1_path: Path to R1 FASTQ file\n        r2_path: Path to R2 FASTQ file  \n        sample_name: Sample name for read group\n        threads: Number of threads to use\n        output_path: Output BAM path (auto-generated if None)\n\n    Returns:\n        Path to sorted BAM file\n\n    Raises:\n        FileNotFoundError: If input files don't exist\n        ExternalToolError: If required tools are not available\n        MappingError: If mapping fails\n\n    Examples:\n        &gt;&gt;&gt; bam_path = map_fastqs(\n        ...     Mapper.MINIMAP2,\n        ...     Path(\"ref.fasta\"),\n        ...     Path(\"sample_R1.fastq.gz\"),\n        ...     Path(\"sample_R2.fastq.gz\"),\n        ...     \"sample123\"\n        ... )\n    \"\"\"\n    # Validate input files\n    for file_path in [fasta_path, r1_path, r2_path]:\n        if not file_path.exists():\n            raise FileNotFoundError(f\"Input file not found: {file_path}\")\n\n    # Check tool availability\n    tools = check_external_tools()\n    tool_name = mapper.value  # Use the actual tool name without modification\n    if not tools.get(tool_name, {}).get('available', False) or not tools.get('samtools', {}).get('available', False):\n        missing = [t for t, info in tools.items() \n                  if not info.get('available', False) and t in [tool_name, 'samtools']]\n        raise ExternalToolError(f\"Required tools not available: {missing}\")\n\n    # Ensure indexes exist\n    ensure_indexes_self(fasta_path, mapper)\n\n    # Generate output path if not provided\n    if output_path is None:\n        output_path = Path(f\"{sample_name}.sorted.bam\")\n\n    logger.info(f\"Mapping {r1_path.name} and {r2_path.name} to {fasta_path.name} using {mapper.value}\")\n\n    try:\n        if mapper == Mapper.MINIMAP2:\n            _map_with_minimap2(fasta_path, r1_path, r2_path, sample_name, threads, output_path)\n        elif mapper == Mapper.BWA_MEM2:\n            _map_with_bwa_mem2(fasta_path, r1_path, r2_path, sample_name, threads, output_path)\n        else:\n            raise ValueError(f\"Unsupported mapper: {mapper}\")\n\n    except subprocess.CalledProcessError as e:\n        raise MappingError(f\"Mapping with {mapper.value} failed: {e}\")\n\n    if not output_path.exists():\n        raise MappingError(f\"Output BAM was not created: {output_path}\")\n\n    # Index the BAM file\n    index_bam(output_path)\n\n    logger.info(f\"Created sorted BAM: {output_path}\")\n    return output_path\n</code></pre>"},{"location":"reference/#variant-calling","title":"Variant Calling","text":"<p>Variant calling module for ssiamb.</p> <p>This module implements variant calling using BBTools and bcftools pipelines. Supports both bacterial genome analysis with appropriate ploidy and quality settings.</p>"},{"location":"reference/#ssiamb.calling.VariantCallResult","title":"<code>VariantCallResult(vcf_path, caller, success, error_message=None, runtime_seconds=None)</code>  <code>dataclass</code>","text":"<p>Result of variant calling operation.</p>"},{"location":"reference/#ssiamb.calling.VariantCallingError","title":"<code>VariantCallingError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when variant calling fails.</p>"},{"location":"reference/#ssiamb.calling.call_variants","title":"<code>call_variants(bam_path, reference_path, output_vcf, caller, sample_name, threads=1, mapq_min=20, baseq_min=20, minallelefraction=0.0, bbtools_mem=None)</code>","text":"<p>Run variant calling with the specified caller.</p> <p>Parameters:</p> Name Type Description Default <code>bam_path</code> <code>Path</code> <p>Input BAM file</p> required <code>reference_path</code> <code>Path</code> <p>Reference genome FASTA</p> required <code>output_vcf</code> <code>Path</code> <p>Output VCF file path</p> required <code>caller</code> <code>Caller</code> <p>Variant caller to use</p> required <code>sample_name</code> <code>str</code> <p>Sample name for VCF header</p> required <code>threads</code> <code>int</code> <p>Number of threads to use</p> <code>1</code> <code>mapq_min</code> <code>int</code> <p>Minimum mapping quality</p> <code>20</code> <code>baseq_min</code> <code>int</code> <p>Minimum base quality</p> <code>20</code> <code>minallelefraction</code> <code>float</code> <p>Minimum allele fraction (BBTools only)</p> <code>0.0</code> <code>bbtools_mem</code> <code>Optional[str]</code> <p>BBTools heap memory (e.g., '4g', '8g')</p> <code>None</code> <p>Returns:</p> Type Description <code>VariantCallResult</code> <p>VariantCallResult with execution details</p> <p>Raises:</p> Type Description <code>VariantCallingError</code> <p>If caller tools are not available or calling fails</p> Source code in <code>src/ssiamb/calling.py</code> <pre><code>def call_variants(\n    bam_path: Path,\n    reference_path: Path,\n    output_vcf: Path,\n    caller: Caller,\n    sample_name: str,\n    threads: int = 1,\n    mapq_min: int = 20,\n    baseq_min: int = 20,\n    minallelefraction: float = 0.0,\n    bbtools_mem: Optional[str] = None,\n) -&gt; VariantCallResult:\n    \"\"\"\n    Run variant calling with the specified caller.\n\n    Args:\n        bam_path: Input BAM file\n        reference_path: Reference genome FASTA\n        output_vcf: Output VCF file path\n        caller: Variant caller to use\n        sample_name: Sample name for VCF header\n        threads: Number of threads to use\n        mapq_min: Minimum mapping quality\n        baseq_min: Minimum base quality\n        minallelefraction: Minimum allele fraction (BBTools only)\n        bbtools_mem: BBTools heap memory (e.g., '4g', '8g')\n\n    Returns:\n        VariantCallResult with execution details\n\n    Raises:\n        VariantCallingError: If caller tools are not available or calling fails\n    \"\"\"\n    # Check tool availability\n    if not caller_tools_available(caller):\n        raise VariantCallingError(f\"Required tools for {caller.value} are not available\")\n\n    # Validate inputs\n    if not bam_path.exists():\n        raise VariantCallingError(f\"BAM file not found: {bam_path}\")\n    if not reference_path.exists():\n        raise VariantCallingError(f\"Reference file not found: {reference_path}\")\n\n    # Run appropriate caller\n    if caller == Caller.BBTOOLS:\n        result = run_bbtools_calling(\n            bam_path=bam_path,\n            reference_path=reference_path,\n            output_vcf=output_vcf,\n            sample_name=sample_name,\n            threads=threads,\n            mapq_min=mapq_min,\n            baseq_min=baseq_min,\n            minallelefraction=minallelefraction,\n            bbtools_mem=bbtools_mem,\n        )\n    elif caller == Caller.BCFTOOLS:\n        result = run_bcftools_calling(\n            bam_path=bam_path,\n            reference_path=reference_path,\n            output_vcf=output_vcf,\n            sample_name=sample_name,\n            threads=threads,\n            mapq_min=mapq_min,\n            baseq_min=baseq_min,\n        )\n    else:\n        raise VariantCallingError(f\"Unsupported caller: {caller}\")\n\n    # Raise exception if calling failed\n    if not result.success:\n        raise VariantCallingError(result.error_message or f\"{caller.value} variant calling failed\")\n\n    return result\n</code></pre>"},{"location":"reference/#ssiamb.calling.caller_tools_available","title":"<code>caller_tools_available(caller)</code>","text":"<p>Check if all required tools for the specified caller are available.</p> <p>Parameters:</p> Name Type Description Default <code>caller</code> <code>Caller</code> <p>Variant caller to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all required tools are available, False otherwise</p> Source code in <code>src/ssiamb/calling.py</code> <pre><code>def caller_tools_available(caller: Caller) -&gt; bool:\n    \"\"\"\n    Check if all required tools for the specified caller are available.\n\n    Args:\n        caller: Variant caller to check\n\n    Returns:\n        True if all required tools are available, False otherwise\n    \"\"\"\n    tools = check_caller_tools_detailed(caller)\n    return all(tool_info.get('available', False) for tool_info in tools.values())\n</code></pre>"},{"location":"reference/#ssiamb.calling.check_caller_tools","title":"<code>check_caller_tools(caller)</code>","text":"<p>Check if required tools for the specified caller are available.</p> <p>Parameters:</p> Name Type Description Default <code>caller</code> <code>Caller</code> <p>Variant caller to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all required tools are available, False otherwise</p> Source code in <code>src/ssiamb/calling.py</code> <pre><code>def check_caller_tools(caller: Caller) -&gt; bool:\n    \"\"\"\n    Check if required tools for the specified caller are available.\n\n    Args:\n        caller: Variant caller to check\n\n    Returns:\n        True if all required tools are available, False otherwise\n    \"\"\"\n    if caller == Caller.BBTOOLS:\n        # Check for BBTools executables\n        return (shutil.which(\"pileup.sh\") is not None and \n                shutil.which(\"callvariants.sh\") is not None)\n    elif caller == Caller.BCFTOOLS:\n        # Check for bcftools\n        return shutil.which(\"bcftools\") is not None\n    else:\n        raise ValueError(f\"Unknown caller: {caller}\")\n</code></pre>"},{"location":"reference/#ssiamb.calling.check_caller_tools_detailed","title":"<code>check_caller_tools_detailed(caller)</code>","text":"<p>Check availability and versions of required tools for the specified caller.</p> <p>Parameters:</p> Name Type Description Default <code>caller</code> <code>Caller</code> <p>Variant caller to check</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, str]]</code> <p>Dictionary mapping tool names to availability and version info.</p> <code>Dict[str, Dict[str, str]]</code> <p>Each tool entry contains:</p> <code>Dict[str, Dict[str, str]]</code> <ul> <li>'available': boolean status</li> </ul> <code>Dict[str, Dict[str, str]]</code> <ul> <li>'version': version string if available, or error message</li> </ul> Source code in <code>src/ssiamb/calling.py</code> <pre><code>def check_caller_tools_detailed(caller: Caller) -&gt; Dict[str, Dict[str, str]]:\n    \"\"\"\n    Check availability and versions of required tools for the specified caller.\n\n    Args:\n        caller: Variant caller to check\n\n    Returns:\n        Dictionary mapping tool names to availability and version info.\n        Each tool entry contains:\n        - 'available': boolean status\n        - 'version': version string if available, or error message\n    \"\"\"\n    tools = {}\n\n    if caller == Caller.BBTOOLS:\n        # Check for BBTools executables\n        for tool in [\"pileup.sh\", \"callvariants.sh\"]:\n            tools[tool] = {'available': False, 'version': 'unknown'}\n\n            if shutil.which(tool) is None:\n                tools[tool]['version'] = 'not found in PATH'\n                logger.debug(f\"Tool {tool}: not found\")\n                continue\n\n            # BBTools scripts typically don't have version commands, so just mark as available\n            tools[tool]['available'] = True\n            tools[tool]['version'] = 'BBTools (version check not supported)'\n            logger.debug(f\"Tool {tool}: available\")\n\n    elif caller == Caller.BCFTOOLS:\n        # Check for bcftools\n        tools['bcftools'] = {'available': False, 'version': 'unknown'}\n\n        if shutil.which(\"bcftools\") is None:\n            tools['bcftools']['version'] = 'not found in PATH'\n            logger.debug(\"Tool bcftools: not found\")\n        else:\n            # Try to get bcftools version\n            try:\n                result = subprocess.run(\n                    ['bcftools', '--version'],\n                    capture_output=True,\n                    text=True,\n                    timeout=5\n                )\n                if result.returncode == 0:\n                    tools['bcftools']['available'] = True\n                    # Extract version from output (first line typically)\n                    version_line = result.stdout.strip().split('\\n')[0] if result.stdout else 'version check succeeded'\n                    tools['bcftools']['version'] = version_line\n                    logger.debug(f\"Tool bcftools: available, version: {version_line}\")\n                else:\n                    tools['bcftools']['version'] = f'version check failed (exit {result.returncode})'\n                    logger.debug(\"Tool bcftools: found but version check failed\")\n            except subprocess.TimeoutExpired:\n                tools['bcftools']['version'] = 'version check timed out'\n                logger.debug(\"Tool bcftools: found but version check timed out\")\n            except Exception as e:\n                tools['bcftools']['version'] = f'version check error: {e}'\n                logger.debug(f\"Tool bcftools: found but version check error: {e}\")\n    else:\n        raise ValueError(f\"Unknown caller: {caller}\")\n\n    return tools\n</code></pre>"},{"location":"reference/#ssiamb.calling.get_available_callers","title":"<code>get_available_callers()</code>","text":"<p>Get list of available variant callers based on tool availability.</p> <p>Returns:</p> Type Description <code>List[Caller]</code> <p>List of available Caller enum values</p> Source code in <code>src/ssiamb/calling.py</code> <pre><code>def get_available_callers() -&gt; List[Caller]:\n    \"\"\"\n    Get list of available variant callers based on tool availability.\n\n    Returns:\n        List of available Caller enum values\n    \"\"\"\n    available = []\n\n    for caller in Caller:\n        if caller_tools_available(caller):\n            available.append(caller)\n\n    return available\n</code></pre>"},{"location":"reference/#ssiamb.calling.run_bbtools_calling","title":"<code>run_bbtools_calling(bam_path, reference_path, output_vcf, sample_name, threads=1, mapq_min=20, baseq_min=20, minallelefraction=0.0, bbtools_mem=None)</code>","text":"<p>Run BBTools variant calling pipeline.</p> <p>Executes: 1. callvariants.sh directly with BAM input (no pileup step needed)</p> <p>Parameters:</p> Name Type Description Default <code>bam_path</code> <code>Path</code> <p>Input BAM file</p> required <code>reference_path</code> <code>Path</code> <p>Reference genome FASTA</p> required <code>output_vcf</code> <code>Path</code> <p>Output VCF file path</p> required <code>sample_name</code> <code>str</code> <p>Sample name for VCF header</p> required <code>threads</code> <code>int</code> <p>Number of threads to use</p> <code>1</code> <code>mapq_min</code> <code>int</code> <p>Minimum mapping quality</p> <code>20</code> <code>baseq_min</code> <code>int</code> <p>Minimum base quality</p> <code>20</code> <code>minallelefraction</code> <code>float</code> <p>Minimum allele fraction for variant calling</p> <code>0.0</code> <code>bbtools_mem</code> <code>Optional[str]</code> <p>BBTools heap memory (e.g., '4g', '8g')</p> <code>None</code> <p>Returns:</p> Type Description <code>VariantCallResult</code> <p>VariantCallResult with execution details</p> Source code in <code>src/ssiamb/calling.py</code> <pre><code>def run_bbtools_calling(\n    bam_path: Path,\n    reference_path: Path,\n    output_vcf: Path,\n    sample_name: str,\n    threads: int = 1,\n    mapq_min: int = 20,\n    baseq_min: int = 20,\n    minallelefraction: float = 0.0,\n    bbtools_mem: Optional[str] = None,\n) -&gt; VariantCallResult:\n    \"\"\"\n    Run BBTools variant calling pipeline.\n\n    Executes:\n    1. callvariants.sh directly with BAM input (no pileup step needed)\n\n    Args:\n        bam_path: Input BAM file\n        reference_path: Reference genome FASTA\n        output_vcf: Output VCF file path\n        sample_name: Sample name for VCF header\n        threads: Number of threads to use\n        mapq_min: Minimum mapping quality\n        baseq_min: Minimum base quality\n        minallelefraction: Minimum allele fraction for variant calling\n        bbtools_mem: BBTools heap memory (e.g., '4g', '8g')\n\n    Returns:\n        VariantCallResult with execution details\n    \"\"\"\n    import time\n    start_time = time.time()\n\n    try:\n        # Ensure output directory exists\n        output_vcf.parent.mkdir(parents=True, exist_ok=True)\n\n        # Run callvariants.sh directly with BAM input (simpler approach)\n        callvariants_cmd = [\n            \"callvariants.sh\",\n            f\"in={bam_path}\",\n            f\"ref={reference_path}\",\n            f\"vcf={output_vcf}\",           # Use vcf= for VCF output\n            \"ploidy=1\",                   # Haploid organism\n            \"clearfilters=t\",             # Clear all filters to get raw variants\n            f\"minallelefraction={minallelefraction}\",\n            f\"minavgmapq={mapq_min}\",\n            f\"minquality={baseq_min}\",\n            f\"threads={threads}\",\n        ]\n\n        # Add memory setting if provided\n        if bbtools_mem:\n            callvariants_cmd.append(f\"-Xmx{bbtools_mem}\")\n\n        logger.info(f\"Running BBTools callvariants: {' '.join(map(str, callvariants_cmd))}\")\n\n        result = subprocess.run(\n            callvariants_cmd,\n            capture_output=True,\n            text=True,\n            check=False,\n            timeout=3600  # 1 hour timeout\n        )\n\n        if result.returncode != 0:\n            error_msg = f\"BBTools callvariants failed (exit {result.returncode}): {result.stderr}\"\n            logger.error(error_msg)\n            return VariantCallResult(\n                vcf_path=output_vcf,\n                caller=Caller.BBTOOLS,\n                success=False,\n                error_message=error_msg,\n                runtime_seconds=time.time() - start_time\n            )\n\n        # Log stdout for debugging\n        if result.stdout:\n            logger.debug(f\"BBTools callvariants stdout: {result.stdout.strip()}\")\n\n        # Verify output VCF was created\n        if not output_vcf.exists() or output_vcf.stat().st_size == 0:\n            error_msg = \"BBTools callvariants completed but no VCF output found\"\n            logger.error(error_msg)\n            return VariantCallResult(\n                vcf_path=output_vcf,\n                caller=Caller.BBTOOLS,\n                success=False,\n                error_message=error_msg,\n                runtime_seconds=time.time() - start_time\n            )\n\n        logger.info(f\"BBTools variant calling completed: {output_vcf}\")\n        return VariantCallResult(\n            vcf_path=output_vcf,\n            caller=Caller.BBTOOLS,\n            success=True,\n            runtime_seconds=time.time() - start_time\n        )\n\n    except subprocess.TimeoutExpired:\n        error_msg = \"BBTools variant calling timed out\"\n        logger.error(error_msg)\n        return VariantCallResult(\n            vcf_path=output_vcf,\n            caller=Caller.BBTOOLS,\n            success=False,\n            error_message=error_msg,\n            runtime_seconds=time.time() - start_time\n        )\n    except Exception as e:\n        error_msg = f\"BBTools variant calling failed with exception: {e}\"\n        logger.error(error_msg)\n        return VariantCallResult(\n            vcf_path=output_vcf,\n            caller=Caller.BBTOOLS,\n            success=False,\n            error_message=error_msg,\n            runtime_seconds=time.time() - start_time\n        )\n</code></pre>"},{"location":"reference/#ssiamb.calling.run_bcftools_calling","title":"<code>run_bcftools_calling(bam_path, reference_path, output_vcf, sample_name, threads=1, mapq_min=20, baseq_min=20)</code>","text":"<p>Run bcftools variant calling pipeline.</p> <p>Executes: 1. bcftools mpileup -q20 -Q20 -B -a AD,ADF,ADR,DP 2. bcftools call -m --ploidy 1</p> <p>Parameters:</p> Name Type Description Default <code>bam_path</code> <code>Path</code> <p>Input BAM file</p> required <code>reference_path</code> <code>Path</code> <p>Reference genome FASTA</p> required <code>output_vcf</code> <code>Path</code> <p>Output VCF file path</p> required <code>sample_name</code> <code>str</code> <p>Sample name for VCF header</p> required <code>threads</code> <code>int</code> <p>Number of threads to use</p> <code>1</code> <code>mapq_min</code> <code>int</code> <p>Minimum mapping quality</p> <code>20</code> <code>baseq_min</code> <code>int</code> <p>Minimum base quality</p> <code>20</code> <p>Returns:</p> Type Description <code>VariantCallResult</code> <p>VariantCallResult with execution details</p> Source code in <code>src/ssiamb/calling.py</code> <pre><code>def run_bcftools_calling(\n    bam_path: Path,\n    reference_path: Path,\n    output_vcf: Path,\n    sample_name: str,\n    threads: int = 1,\n    mapq_min: int = 20,\n    baseq_min: int = 20,\n) -&gt; VariantCallResult:\n    \"\"\"\n    Run bcftools variant calling pipeline.\n\n    Executes:\n    1. bcftools mpileup -q20 -Q20 -B -a AD,ADF,ADR,DP\n    2. bcftools call -m --ploidy 1\n\n    Args:\n        bam_path: Input BAM file\n        reference_path: Reference genome FASTA\n        output_vcf: Output VCF file path\n        sample_name: Sample name for VCF header\n        threads: Number of threads to use\n        mapq_min: Minimum mapping quality\n        baseq_min: Minimum base quality\n\n    Returns:\n        VariantCallResult with execution details\n    \"\"\"\n    import time\n    start_time = time.time()\n\n    try:\n        # Ensure output directory exists\n        output_vcf.parent.mkdir(parents=True, exist_ok=True)\n\n        # Combine mpileup and call in a pipeline\n        mpileup_cmd = [\n            \"bcftools\", \"mpileup\",\n            \"-Ou\",                     # Uncompressed BCF output (required by spec)\n            f\"--threads\", str(threads),\n            f\"-q\", str(mapq_min),      # Minimum mapping quality\n            f\"-Q\", str(baseq_min),     # Minimum base quality\n            \"-B\",                      # Disable BAQ computation\n            \"--max-depth\", \"100000\",   # Maximum depth (required by spec)\n            \"-a\", \"FORMAT/AD,ADF,ADR,DP\",  # Annotations to include (fixed format)\n            \"-f\", str(reference_path),  # Reference FASTA\n            str(bam_path)              # Input BAM\n        ]\n\n        call_cmd = [\n            \"bcftools\", \"call\",\n            f\"--threads\", str(threads),\n            \"-m\",                      # Multiallelic caller\n            \"--ploidy\", \"1\",           # Haploid organism\n            \"--prior\", \"1.1e-3\",       # Prior for novel mutation rate (required by spec)\n            \"-v\",                      # Output only variants\n            \"-o\", str(output_vcf)      # Output file\n        ]\n\n        logger.info(f\"Running bcftools pipeline: {' '.join(mpileup_cmd)} | {' '.join(call_cmd)}\")\n\n        # Run mpileup | call pipeline\n        mpileup_proc = subprocess.Popen(\n            mpileup_cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True\n        )\n\n        call_proc = subprocess.Popen(\n            call_cmd,\n            stdin=mpileup_proc.stdout,\n            stderr=subprocess.PIPE,\n            text=True\n        )\n\n        # Close mpileup stdout to allow it to receive SIGPIPE\n        if mpileup_proc.stdout:\n            mpileup_proc.stdout.close()\n\n        # Wait for both processes\n        call_stderr = call_proc.communicate()[1]\n        mpileup_stderr = mpileup_proc.communicate()[1]\n\n        # Check return codes\n        if mpileup_proc.returncode != 0:\n            error_msg = f\"bcftools mpileup failed (exit {mpileup_proc.returncode}): {mpileup_stderr}\"\n            logger.error(error_msg)\n            return VariantCallResult(\n                vcf_path=output_vcf,\n                caller=Caller.BCFTOOLS,\n                success=False,\n                error_message=error_msg,\n                runtime_seconds=time.time() - start_time\n            )\n\n        if call_proc.returncode != 0:\n            error_msg = f\"bcftools call failed (exit {call_proc.returncode}): {call_stderr}\"\n            logger.error(error_msg)\n            return VariantCallResult(\n                vcf_path=output_vcf,\n                caller=Caller.BCFTOOLS,\n                success=False,\n                error_message=error_msg,\n                runtime_seconds=time.time() - start_time\n            )\n\n        # Verify output VCF was created\n        if not output_vcf.exists():\n            error_msg = \"bcftools call completed but no VCF output found\"\n            logger.error(error_msg)\n            return VariantCallResult(\n                vcf_path=output_vcf,\n                caller=Caller.BCFTOOLS,\n                success=False,\n                error_message=error_msg,\n                runtime_seconds=time.time() - start_time\n            )\n\n        logger.info(f\"bcftools variant calling completed: {output_vcf}\")\n        return VariantCallResult(\n            vcf_path=output_vcf,\n            caller=Caller.BCFTOOLS,\n            success=True,\n            runtime_seconds=time.time() - start_time\n        )\n\n    except Exception as e:\n        error_msg = f\"bcftools variant calling failed with exception: {e}\"\n        logger.error(error_msg)\n        return VariantCallResult(\n            vcf_path=output_vcf,\n            caller=Caller.BCFTOOLS,\n            success=False,\n            error_message=error_msg,\n            runtime_seconds=time.time() - start_time\n        )\n</code></pre>"},{"location":"reference/#depth-analysis","title":"Depth Analysis","text":"<p>Depth analysis using mosdepth for computing denominator metrics.</p> <p>This module provides functionality for: - Running mosdepth on BAM files to compute depth statistics - Parsing mosdepth summary output files - Computing callable bases, genome length, breadth, and mean depth - Filtering contigs by size (\u2265500 bp) for consistent numerator/denominator</p>"},{"location":"reference/#ssiamb.depth.ContigDepthStats","title":"<code>ContigDepthStats(name, length, bases_covered, mean_depth, breadth_10x)</code>  <code>dataclass</code>","text":"<p>Depth statistics for a single contig.</p>"},{"location":"reference/#ssiamb.depth.ContigDepthStats.is_long_enough","title":"<code>is_long_enough</code>  <code>property</code>","text":"<p>Check if contig meets minimum length threshold (\u2265500 bp).</p>"},{"location":"reference/#ssiamb.depth.DepthAnalysisError","title":"<code>DepthAnalysisError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when depth analysis operations fail.</p>"},{"location":"reference/#ssiamb.depth.DepthSummary","title":"<code>DepthSummary(callable_bases, genome_length, breadth_10x, mean_depth, total_contigs, included_contigs, contig_stats)</code>  <code>dataclass</code>","text":"<p>Summary of depth analysis results.</p>"},{"location":"reference/#ssiamb.depth.DepthSummary.included_contig_names","title":"<code>included_contig_names</code>  <code>property</code>","text":"<p>Set of contig names that meet length threshold.</p>"},{"location":"reference/#ssiamb.depth.analyze_depth","title":"<code>analyze_depth(bam_path, output_dir, sample_name, mapq_threshold=30, depth_threshold=10, threads=4)</code>","text":"<p>Complete depth analysis workflow: run mosdepth and parse results.</p> <p>Parameters:</p> Name Type Description Default <code>bam_path</code> <code>Path</code> <p>Path to input BAM file</p> required <code>output_dir</code> <code>Path</code> <p>Directory for output files</p> required <code>sample_name</code> <code>str</code> <p>Sample name for output prefix</p> required <code>mapq_threshold</code> <code>int</code> <p>Minimum mapping quality (default: 30)</p> <code>30</code> <code>depth_threshold</code> <code>int</code> <p>Depth threshold for breadth calculation (default: 10)</p> <code>10</code> <code>threads</code> <code>int</code> <p>Number of threads to use</p> <code>4</code> <p>Returns:</p> Type Description <code>DepthSummary</code> <p>DepthSummary object with computed statistics</p> <p>Raises:</p> Type Description <code>DepthAnalysisError</code> <p>If analysis fails at any step</p> Source code in <code>src/ssiamb/depth.py</code> <pre><code>def analyze_depth(\n    bam_path: Path,\n    output_dir: Path,\n    sample_name: str,\n    mapq_threshold: int = 30,\n    depth_threshold: int = 10,\n    threads: int = 4\n) -&gt; DepthSummary:\n    \"\"\"\n    Complete depth analysis workflow: run mosdepth and parse results.\n\n    Args:\n        bam_path: Path to input BAM file\n        output_dir: Directory for output files\n        sample_name: Sample name for output prefix\n        mapq_threshold: Minimum mapping quality (default: 30)\n        depth_threshold: Depth threshold for breadth calculation (default: 10)\n        threads: Number of threads to use\n\n    Returns:\n        DepthSummary object with computed statistics\n\n    Raises:\n        DepthAnalysisError: If analysis fails at any step\n    \"\"\"\n    logger.info(f\"Starting depth analysis for {sample_name}\")\n\n    # Create output directory if needed\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Run mosdepth\n    output_prefix = output_dir / f\"{sample_name}.depth\"\n    summary_file = run_mosdepth(\n        bam_path=bam_path,\n        output_prefix=output_prefix,\n        mapq_threshold=mapq_threshold,\n        threads=threads\n    )\n\n    # Parse results\n    summary = parse_mosdepth_summary(summary_file)\n\n    logger.info(f\"Depth analysis complete for {sample_name}: \"\n               f\"{summary.genome_length:,} bp genome, \"\n               f\"{summary.breadth_10x:.2%} breadth \u2265{depth_threshold}x\")\n\n    return summary\n</code></pre>"},{"location":"reference/#ssiamb.depth.check_mosdepth_available","title":"<code>check_mosdepth_available()</code>","text":"<p>Check if mosdepth is available in PATH.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if mosdepth is available, False otherwise</p> Source code in <code>src/ssiamb/depth.py</code> <pre><code>def check_mosdepth_available() -&gt; bool:\n    \"\"\"\n    Check if mosdepth is available in PATH.\n\n    Returns:\n        True if mosdepth is available, False otherwise\n    \"\"\"\n    try:\n        subprocess.run(['mosdepth', '--version'], \n                      capture_output=True, check=True)\n        return True\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        return False\n</code></pre>"},{"location":"reference/#ssiamb.depth.get_depth_from_existing_summary","title":"<code>get_depth_from_existing_summary(summary_file)</code>","text":"<p>Parse existing mosdepth summary file without running mosdepth.</p> <p>Useful for reusing existing depth analysis results.</p> <p>Parameters:</p> Name Type Description Default <code>summary_file</code> <code>Path</code> <p>Path to existing .mosdepth.summary.txt file</p> required <p>Returns:</p> Type Description <code>DepthSummary</code> <p>DepthSummary object with computed statistics</p> Source code in <code>src/ssiamb/depth.py</code> <pre><code>def get_depth_from_existing_summary(summary_file: Path) -&gt; DepthSummary:\n    \"\"\"\n    Parse existing mosdepth summary file without running mosdepth.\n\n    Useful for reusing existing depth analysis results.\n\n    Args:\n        summary_file: Path to existing .mosdepth.summary.txt file\n\n    Returns:\n        DepthSummary object with computed statistics\n    \"\"\"\n    return parse_mosdepth_summary(summary_file)\n</code></pre>"},{"location":"reference/#ssiamb.depth.list_included_contigs","title":"<code>list_included_contigs(summary_file, min_len=500)</code>","text":"<p>Get set of contig names that meet minimum length threshold.</p> <p>Parameters:</p> Name Type Description Default <code>summary_file</code> <code>Path</code> <p>Path to .mosdepth.summary.txt file</p> required <code>min_len</code> <code>int</code> <p>Minimum contig length threshold</p> <code>500</code> <p>Returns:</p> Type Description <code>Set[str]</code> <p>Set of contig names that meet the length threshold</p> Source code in <code>src/ssiamb/depth.py</code> <pre><code>def list_included_contigs(summary_file: Path, min_len: int = 500) -&gt; Set[str]:\n    \"\"\"\n    Get set of contig names that meet minimum length threshold.\n\n    Args:\n        summary_file: Path to .mosdepth.summary.txt file\n        min_len: Minimum contig length threshold\n\n    Returns:\n        Set of contig names that meet the length threshold\n    \"\"\"\n    if not summary_file.exists():\n        logger.warning(f\"Summary file not found: {summary_file}\")\n        return set()\n\n    try:\n        included_contigs = set()\n\n        with open(summary_file, 'r') as f:\n            for line in f:\n                line = line.strip()\n                if not line or line.startswith('#'):\n                    continue\n\n                fields = line.split('\\t')\n                if len(fields) &lt; 4:\n                    continue\n\n                contig_name = fields[0]\n                try:\n                    contig_length = int(fields[1])\n                    if contig_length &gt;= min_len:\n                        included_contigs.add(contig_name)\n                except (ValueError, IndexError):\n                    continue\n\n        logger.debug(f\"Found {len(included_contigs)} contigs &gt;= {min_len} bp\")\n        return included_contigs\n\n    except Exception as e:\n        logger.error(f\"Error reading mosdepth summary {summary_file}: {e}\")\n        return set()\n</code></pre>"},{"location":"reference/#ssiamb.depth.parse_mosdepth_summary","title":"<code>parse_mosdepth_summary(summary_file)</code>","text":"<p>Parse mosdepth summary file to extract depth statistics.</p> <p>The mosdepth summary file has format: chrom       length  bases   mean    min     max contig1     5000    4850    25.3    0       100 ... total       50000   48500   24.8    0       100</p> <p>Parameters:</p> Name Type Description Default <code>summary_file</code> <code>Path</code> <p>Path to .mosdepth.summary.txt file</p> required <p>Returns:</p> Type Description <code>DepthSummary</code> <p>DepthSummary object with computed statistics</p> <p>Raises:</p> Type Description <code>DepthAnalysisError</code> <p>If file parsing fails</p> <code>FileNotFoundError</code> <p>If summary file doesn't exist</p> Source code in <code>src/ssiamb/depth.py</code> <pre><code>def parse_mosdepth_summary(summary_file: Path) -&gt; DepthSummary:\n    \"\"\"\n    Parse mosdepth summary file to extract depth statistics.\n\n    The mosdepth summary file has format:\n    chrom\tlength\tbases\tmean\tmin\tmax\n    contig1\t5000\t4850\t25.3\t0\t100\n    ...\n    total\t50000\t48500\t24.8\t0\t100\n\n    Args:\n        summary_file: Path to .mosdepth.summary.txt file\n\n    Returns:\n        DepthSummary object with computed statistics\n\n    Raises:\n        DepthAnalysisError: If file parsing fails\n        FileNotFoundError: If summary file doesn't exist\n    \"\"\"\n    if not summary_file.exists():\n        raise FileNotFoundError(f\"mosdepth summary file not found: {summary_file}\")\n\n    logger.info(f\"Parsing mosdepth summary: {summary_file}\")\n\n    try:\n        contig_stats = []\n        total_line = None\n\n        with open(summary_file, 'r') as f:\n            # Skip header line\n            header = f.readline().strip()\n            if not header.startswith('chrom'):\n                raise DepthAnalysisError(f\"Unexpected header format: {header}\")\n\n            for line_num, line in enumerate(f, start=2):\n                line = line.strip()\n                if not line:\n                    continue\n\n                parts = line.split('\\t')\n                if len(parts) &lt; 4:\n                    raise DepthAnalysisError(f\"Invalid line format at line {line_num}: {line}\")\n\n                chrom, length_str, bases_str, mean_str = parts[:4]\n\n                try:\n                    length = int(length_str)\n                    bases_covered = int(bases_str)\n                    mean_depth = float(mean_str)\n                except ValueError as e:\n                    raise DepthAnalysisError(f\"Invalid numeric value at line {line_num}: {e}\")\n\n                if chrom == 'total':\n                    total_line = (length, bases_covered, mean_depth)\n                else:\n                    # Calculate breadth for this contig\n                    breadth_10x = bases_covered / length if length &gt; 0 else 0.0\n\n                    contig_stats.append(ContigDepthStats(\n                        name=chrom,\n                        length=length,\n                        bases_covered=bases_covered,\n                        mean_depth=mean_depth,\n                        breadth_10x=breadth_10x\n                    ))\n\n        if not contig_stats:\n            raise DepthAnalysisError(\"No contig data found in summary file\")\n\n        # Compute summary statistics for contigs \u2265500bp\n        long_contigs = [c for c in contig_stats if c.is_long_enough]\n\n        if not long_contigs:\n            logger.warning(\"No contigs \u2265500bp found - all contigs are too short\")\n            genome_length = 0\n            callable_bases = 0\n            breadth_10x = 0.0\n            mean_depth = 0.0\n        else:\n            genome_length = sum(c.length for c in long_contigs)\n            callable_bases = sum(c.bases_covered for c in long_contigs)\n            breadth_10x = callable_bases / genome_length if genome_length &gt; 0 else 0.0\n\n            # Weighted mean depth across long contigs\n            total_depth = sum(c.mean_depth * c.length for c in long_contigs)\n            mean_depth = total_depth / genome_length if genome_length &gt; 0 else 0.0\n\n        summary = DepthSummary(\n            callable_bases=callable_bases,\n            genome_length=genome_length,\n            breadth_10x=breadth_10x,\n            mean_depth=mean_depth,\n            total_contigs=len(contig_stats),\n            included_contigs=len(long_contigs),\n            contig_stats=contig_stats\n        )\n\n        logger.info(f\"Parsed depth summary: {summary.included_contigs}/{summary.total_contigs} contigs \u2265500bp, \"\n                   f\"{summary.callable_bases:,} callable bases, {summary.mean_depth:.1f}x mean depth\")\n\n        return summary\n\n    except Exception as e:\n        if isinstance(e, DepthAnalysisError):\n            raise\n        raise DepthAnalysisError(f\"Failed to parse mosdepth summary: {e}\")\n</code></pre>"},{"location":"reference/#ssiamb.depth.run_mosdepth","title":"<code>run_mosdepth(bam_path, output_prefix, mapq_threshold=30, threads=4)</code>","text":"<p>Run mosdepth on a BAM file to compute depth statistics.</p> <p>Parameters:</p> Name Type Description Default <code>bam_path</code> <code>Path</code> <p>Path to input BAM file</p> required <code>output_prefix</code> <code>Path</code> <p>Output prefix for mosdepth files</p> required <code>mapq_threshold</code> <code>int</code> <p>Minimum mapping quality (default: 30)</p> <code>30</code> <code>threads</code> <code>int</code> <p>Number of threads to use</p> <code>4</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the generated summary file (.mosdepth.summary.txt)</p> <p>Raises:</p> Type Description <code>DepthAnalysisError</code> <p>If mosdepth is not available or execution fails</p> <code>FileNotFoundError</code> <p>If BAM file doesn't exist</p> Source code in <code>src/ssiamb/depth.py</code> <pre><code>def run_mosdepth(\n    bam_path: Path,\n    output_prefix: Path,\n    mapq_threshold: int = 30,\n    threads: int = 4\n) -&gt; Path:\n    \"\"\"\n    Run mosdepth on a BAM file to compute depth statistics.\n\n    Args:\n        bam_path: Path to input BAM file\n        output_prefix: Output prefix for mosdepth files\n        mapq_threshold: Minimum mapping quality (default: 30)\n        threads: Number of threads to use\n\n    Returns:\n        Path to the generated summary file (.mosdepth.summary.txt)\n\n    Raises:\n        DepthAnalysisError: If mosdepth is not available or execution fails\n        FileNotFoundError: If BAM file doesn't exist\n    \"\"\"\n    if not bam_path.exists():\n        raise FileNotFoundError(f\"BAM file not found: {bam_path}\")\n\n    if not check_mosdepth_available():\n        raise DepthAnalysisError(\"mosdepth not found in PATH\")\n\n    # Construct mosdepth command\n    cmd = [\n        'mosdepth',\n        '--mapq', str(mapq_threshold),\n        '--no-per-base',  # Skip per-base output for efficiency\n        '--threads', str(threads),\n        str(output_prefix),\n        str(bam_path)\n    ]\n\n    logger.info(f\"Running mosdepth: {' '.join(cmd)}\")\n\n    try:\n        result = subprocess.run(\n            cmd, \n            capture_output=True, \n            text=True, \n            check=True\n        )\n\n        # Log any stderr output for debugging\n        if result.stderr.strip():\n            logger.debug(f\"mosdepth stderr: {result.stderr.strip()}\")\n\n    except subprocess.CalledProcessError as e:\n        error_msg = f\"mosdepth failed with return code {e.returncode}\"\n        if e.stderr:\n            error_msg += f\": {e.stderr.strip()}\"\n        raise DepthAnalysisError(error_msg)\n\n    # Check that expected output file was created\n    summary_file = Path(str(output_prefix) + '.mosdepth.summary.txt')\n    if not summary_file.exists():\n        raise DepthAnalysisError(f\"Expected mosdepth summary file not created: {summary_file}\")\n\n    logger.info(f\"mosdepth completed successfully: {summary_file}\")\n    return summary_file\n</code></pre>"},{"location":"reference/#quality-control","title":"Quality Control","text":"<p>Quality control policies and warning thresholds for ssiamb.</p> <p>This module implements QC policies that warn but do not fail runs, as specified in spec.md \u00a78.</p>"},{"location":"reference/#ssiamb.qc.QCThresholds","title":"<code>QCThresholds(min_breadth_10x=0.8, min_callable_bases=1000000, min_mapping_rate_ref=0.7)</code>  <code>dataclass</code>","text":"<p>QC warning thresholds as specified in spec.md \u00a78.</p>"},{"location":"reference/#ssiamb.qc.QCWarning","title":"<code>QCWarning(metric, value, threshold, message)</code>  <code>dataclass</code>","text":"<p>A QC warning with message and metric values.</p>"},{"location":"reference/#ssiamb.qc.check_qc_metrics","title":"<code>check_qc_metrics(breadth_10x, callable_bases, mapping_rate=None, mode=None, thresholds=None)</code>","text":"<p>Check QC metrics against warning thresholds.</p> <p>Parameters:</p> Name Type Description Default <code>breadth_10x</code> <code>float</code> <p>Breadth of coverage at 10x depth (0.0-1.0)</p> required <code>callable_bases</code> <code>int</code> <p>Number of callable bases</p> required <code>mapping_rate</code> <code>Optional[float]</code> <p>Mapping rate (0.0-1.0), required for ref mode</p> <code>None</code> <code>mode</code> <code>Optional[Mode]</code> <p>Analysis mode (used to determine if mapping rate applies)</p> <code>None</code> <code>thresholds</code> <code>Optional[QCThresholds]</code> <p>QC thresholds (uses defaults if None)</p> <code>None</code> <p>Returns:</p> Type Description <code>List[QCWarning]</code> <p>List of QC warnings</p> Source code in <code>src/ssiamb/qc.py</code> <pre><code>def check_qc_metrics(\n    breadth_10x: float,\n    callable_bases: int,\n    mapping_rate: Optional[float] = None,\n    mode: Optional[Mode] = None,\n    thresholds: Optional[QCThresholds] = None\n) -&gt; List[QCWarning]:\n    \"\"\"\n    Check QC metrics against warning thresholds.\n\n    Args:\n        breadth_10x: Breadth of coverage at 10x depth (0.0-1.0)\n        callable_bases: Number of callable bases\n        mapping_rate: Mapping rate (0.0-1.0), required for ref mode\n        mode: Analysis mode (used to determine if mapping rate applies)\n        thresholds: QC thresholds (uses defaults if None)\n\n    Returns:\n        List of QC warnings\n    \"\"\"\n    if thresholds is None:\n        thresholds = QCThresholds()\n\n    warnings = []\n\n    # Check breadth_10x threshold\n    if breadth_10x &lt; thresholds.min_breadth_10x:\n        warnings.append(QCWarning(\n            metric=\"breadth_10x\",\n            value=breadth_10x,\n            threshold=thresholds.min_breadth_10x,\n            message=f\"Low breadth of coverage at 10x: {breadth_10x:.3f} &lt; {thresholds.min_breadth_10x:.3f}\"\n        ))\n\n    # Check callable bases threshold\n    if callable_bases &lt; thresholds.min_callable_bases:\n        warnings.append(QCWarning(\n            metric=\"callable_bases\",\n            value=callable_bases,\n            threshold=thresholds.min_callable_bases,\n            message=f\"Low callable bases: {callable_bases:,} &lt; {thresholds.min_callable_bases:,}\"\n        ))\n\n    # Check mapping rate threshold (ref mode only)\n    if mode == Mode.REF and mapping_rate is not None:\n        if mapping_rate &lt; thresholds.min_mapping_rate_ref:\n            warnings.append(QCWarning(\n                metric=\"mapping_rate\",\n                value=mapping_rate,\n                threshold=thresholds.min_mapping_rate_ref,\n                message=f\"Low mapping rate in ref mode: {mapping_rate:.3f} &lt; {thresholds.min_mapping_rate_ref:.3f}\"\n            ))\n\n    return warnings\n</code></pre>"},{"location":"reference/#ssiamb.qc.format_qc_warnings_for_summary","title":"<code>format_qc_warnings_for_summary(warnings)</code>","text":"<p>Format QC warnings for inclusion in summary TSV qc_warnings field.</p> <p>Parameters:</p> Name Type Description Default <code>warnings</code> <code>List[QCWarning]</code> <p>List of QC warnings</p> required <p>Returns:</p> Type Description <code>str</code> <p>Semicolon-separated string of warning codes, or empty string if no warnings</p> Source code in <code>src/ssiamb/qc.py</code> <pre><code>def format_qc_warnings_for_summary(warnings: List[QCWarning]) -&gt; str:\n    \"\"\"\n    Format QC warnings for inclusion in summary TSV qc_warnings field.\n\n    Args:\n        warnings: List of QC warnings\n\n    Returns:\n        Semicolon-separated string of warning codes, or empty string if no warnings\n    \"\"\"\n    if not warnings:\n        return \"\"\n\n    # Create concise warning codes\n    codes = []\n    for warning in warnings:\n        if warning.metric == \"breadth_10x\":\n            codes.append(f\"low_breadth_{warning.value:.2f}\")\n        elif warning.metric == \"callable_bases\":\n            codes.append(f\"low_callable_{warning.value:.0e}\")\n        elif warning.metric == \"mapping_rate\":\n            codes.append(f\"low_maprate_{warning.value:.2f}\")\n\n    return \";\".join(codes)\n</code></pre>"},{"location":"reference/#ssiamb.qc.log_qc_warnings","title":"<code>log_qc_warnings(warnings)</code>","text":"<p>Log QC warnings to the logger.</p> <p>Parameters:</p> Name Type Description Default <code>warnings</code> <code>List[QCWarning]</code> <p>List of QC warnings to log</p> required Source code in <code>src/ssiamb/qc.py</code> <pre><code>def log_qc_warnings(warnings: List[QCWarning]) -&gt; None:\n    \"\"\"\n    Log QC warnings to the logger.\n\n    Args:\n        warnings: List of QC warnings to log\n    \"\"\"\n    if not warnings:\n        logger.info(\"All QC metrics passed warning thresholds\")\n        return\n\n    logger.warning(f\"QC warnings detected ({len(warnings)} issues):\")\n    for warning in warnings:\n        logger.warning(f\"  - {warning.message}\")\n</code></pre>"},{"location":"reference/#vcf-operations","title":"VCF Operations","text":"<p>VCF operations module for ssiamb.</p> <p>This module implements VCF normalization, atomization, MAF extraction, variant classification, and grid-based counting for ambiguous sites.</p>"},{"location":"reference/#ssiamb.vcf_ops.AmbigGrid","title":"<code>AmbigGrid(dp_cap=100)</code>","text":"<p>100\u00d751 cumulative grid for ambiguous site counting.</p> <p>Tracks sites by depth (0-100, with capping) and MAF bins (0-50, representing 0.00-0.50). MAF binning: bin = floor(100 * MAF), capped at 50.</p> <p>Initialize grid.</p> <p>Parameters:</p> Name Type Description Default <code>dp_cap</code> <code>int</code> <p>Maximum depth value (higher values are capped)</p> <code>100</code> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def __init__(self, dp_cap: int = 100):\n    \"\"\"\n    Initialize grid.\n\n    Args:\n        dp_cap: Maximum depth value (higher values are capped)\n    \"\"\"\n    self.dp_cap = dp_cap\n    self.maf_bins = 51  # 0.00 to 0.50 in 0.01 increments\n\n    # Grid: [depth][maf_bin] = count\n    self.grid = np.zeros((dp_cap + 1, self.maf_bins), dtype=int)\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.AmbigGrid.add_site","title":"<code>add_site(depth, maf)</code>","text":"<p>Add a site to the grid.</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>int</code> <p>Site depth (will be capped at dp_cap)</p> required <code>maf</code> <code>float</code> <p>Minor allele frequency (0.0 to 1.0)</p> required Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def add_site(self, depth: int, maf: float) -&gt; None:\n    \"\"\"\n    Add a site to the grid.\n\n    Args:\n        depth: Site depth (will be capped at dp_cap)\n        maf: Minor allele frequency (0.0 to 1.0)\n    \"\"\"\n    # Cap depth\n    if depth &gt; self.dp_cap:\n        depth = self.dp_cap\n        logger.debug(f\"Depth capped at {self.dp_cap}\")\n\n    # Calculate MAF bin (floor of 100 * MAF)\n    maf_bin = int(np.floor(100 * maf))\n\n    # Cap MAF bin at 50 (representing 0.50)\n    if maf_bin &gt;= self.maf_bins:\n        maf_bin = self.maf_bins - 1\n\n    # Ensure non-negative\n    depth = max(0, depth)\n    maf_bin = max(0, maf_bin)\n\n    self.grid[depth, maf_bin] += 1\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.AmbigGrid.build_cumulative","title":"<code>build_cumulative()</code>","text":"<p>Build cumulative counts matrix.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Cumulative grid where each cell contains count of sites </p> <code>ndarray</code> <p>with depth &gt;= row_index and MAF &gt;= col_index/100</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def build_cumulative(self) -&gt; np.ndarray:\n    \"\"\"\n    Build cumulative counts matrix.\n\n    Returns:\n        Cumulative grid where each cell contains count of sites \n        with depth &gt;= row_index and MAF &gt;= col_index/100\n    \"\"\"\n    # Start from bottom-right and work backwards\n    cumulative = np.zeros_like(self.grid)\n\n    for dp in range(self.dp_cap, -1, -1):\n        for maf_bin in range(self.maf_bins - 1, -1, -1):\n            cumulative[dp, maf_bin] = self.grid[dp, maf_bin]\n\n            # Add counts from higher depth (same MAF bin)\n            if dp &lt; self.dp_cap:\n                cumulative[dp, maf_bin] += cumulative[dp + 1, maf_bin]\n\n            # Add counts from higher MAF bin (same depth)\n            if maf_bin &lt; self.maf_bins - 1:\n                cumulative[dp, maf_bin] += cumulative[dp, maf_bin + 1]\n\n            # Subtract double-counted intersection\n            if dp &lt; self.dp_cap and maf_bin &lt; self.maf_bins - 1:\n                cumulative[dp, maf_bin] -= cumulative[dp + 1, maf_bin + 1]\n\n    return cumulative\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.AmbigGrid.count_at","title":"<code>count_at(dp_min, maf_min)</code>","text":"<p>Count sites meeting minimum thresholds.</p> <p>Parameters:</p> Name Type Description Default <code>dp_min</code> <code>int</code> <p>Minimum depth threshold</p> required <code>maf_min</code> <code>float</code> <p>Minimum MAF threshold</p> required <p>Returns:</p> Type Description <code>int</code> <p>Count of sites with depth &gt;= dp_min and MAF &gt;= maf_min</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def count_at(self, dp_min: int, maf_min: float) -&gt; int:\n    \"\"\"\n    Count sites meeting minimum thresholds.\n\n    Args:\n        dp_min: Minimum depth threshold\n        maf_min: Minimum MAF threshold\n\n    Returns:\n        Count of sites with depth &gt;= dp_min and MAF &gt;= maf_min\n    \"\"\"\n    cumulative = self.build_cumulative()\n\n    # Convert MAF to bin (floor of 100 * MAF)\n    maf_bin = int(np.floor(100 * maf_min))\n    maf_bin = min(maf_bin, self.maf_bins - 1)\n\n    # Cap depth\n    dp_min = min(dp_min, self.dp_cap)\n\n    return int(cumulative[dp_min, maf_bin])\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.AmbigGrid.to_wide_tsv","title":"<code>to_wide_tsv(output_path)</code>","text":"<p>Write cumulative grid to wide TSV format.</p> <p>Per spec.md \u00a74.4: \"Wide table: rows depth=1..100; columns maf_0..maf_50\"</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>Path</code> <p>Output file path</p> required Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def to_wide_tsv(self, output_path: Path) -&gt; None:\n    \"\"\"\n    Write cumulative grid to wide TSV format.\n\n    Per spec.md \u00a74.4: \"Wide table: rows depth=1..100; columns maf_0..maf_50\"\n\n    Args:\n        output_path: Output file path\n    \"\"\"\n    cumulative = self.build_cumulative()\n\n    # Create header: depth, then MAF columns (0.00, 0.01, ..., 0.50)\n    maf_headers = [f\"{i/100:.2f}\" for i in range(self.maf_bins)]\n    header = [\"depth\"] + maf_headers\n\n    with open(output_path, 'w') as f:\n        # Write header\n        f.write('\\t'.join(header) + '\\n')\n\n        # Write data rows - start from depth=1, not depth=0 (per spec \u00a74.4)\n        for dp in range(1, self.dp_cap + 1):\n            row = [str(dp)] + [str(cumulative[dp, maf_bin]) for maf_bin in range(self.maf_bins)]\n            f.write('\\t'.join(row) + '\\n')\n\n    logger.info(f\"Cumulative grid written to {output_path}\")\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.SiteRecord","title":"<code>SiteRecord(chrom, pos, ref, alt, variant_class, depth, maf, original_filter)</code>  <code>dataclass</code>","text":"<p>Record for a genomic site with variant information.</p>"},{"location":"reference/#ssiamb.vcf_ops.VCFNormalizationResult","title":"<code>VCFNormalizationResult(normalized_vcf_path, success, error_message=None, records_processed=0)</code>  <code>dataclass</code>","text":"<p>Result of VCF normalization operation.</p>"},{"location":"reference/#ssiamb.vcf_ops.VCFOperationError","title":"<code>VCFOperationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when VCF operations fail.</p>"},{"location":"reference/#ssiamb.vcf_ops.VariantClass","title":"<code>VariantClass</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Variant classification types.</p>"},{"location":"reference/#ssiamb.vcf_ops.check_vcf_tools","title":"<code>check_vcf_tools()</code>","text":"<p>Check if required VCF processing tools are available.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if all required tools are available, False otherwise</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def check_vcf_tools() -&gt; bool:\n    \"\"\"\n    Check if required VCF processing tools are available.\n\n    Returns:\n        True if all required tools are available, False otherwise\n    \"\"\"\n    required_tools = [\"bcftools\", \"bgzip\", \"tabix\"]\n    return all(shutil.which(tool) is not None for tool in required_tools)\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.classify_variant","title":"<code>classify_variant(ref, alt)</code>","text":"<p>Classify variant type based on REF and ALT alleles.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>str</code> <p>Reference allele</p> required <code>alt</code> <code>str</code> <p>Alternative allele</p> required <p>Returns:</p> Type Description <code>VariantClass</code> <p>VariantClass enum value</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def classify_variant(ref: str, alt: str) -&gt; VariantClass:\n    \"\"\"\n    Classify variant type based on REF and ALT alleles.\n\n    Args:\n        ref: Reference allele\n        alt: Alternative allele\n\n    Returns:\n        VariantClass enum value\n    \"\"\"\n    # Skip symbolic alleles and IUPAC codes\n    if any(c in ref + alt for c in [\"&lt;\", \"&gt;\", \"*\", \"N\"]):\n        return VariantClass.UNKNOWN\n\n    # Skip non-ATCG characters\n    valid_bases = set(\"ATCG\")\n    if not (set(ref.upper()) &lt;= valid_bases and set(alt.upper()) &lt;= valid_bases):\n        return VariantClass.UNKNOWN\n\n    ref_len = len(ref)\n    alt_len = len(alt)\n\n    if ref_len == alt_len == 1:\n        return VariantClass.SNV\n    elif alt_len &gt; ref_len:\n        return VariantClass.INS\n    elif alt_len &lt; ref_len:\n        return VariantClass.DEL\n    else:\n        # Complex variants\n        return VariantClass.UNKNOWN\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.count_ambiguous_sites","title":"<code>count_ambiguous_sites(vcf_path, dp_min, maf_min, dp_cap=100, included_contigs=None, variant_classes=None)</code>","text":"<p>Count ambiguous sites from normalized VCF.</p> <p>Parameters:</p> Name Type Description Default <code>vcf_path</code> <code>Path</code> <p>Path to normalized VCF file</p> required <code>dp_min</code> <code>int</code> <p>Minimum depth threshold</p> required <code>maf_min</code> <code>float</code> <p>Minimum MAF threshold  </p> required <code>dp_cap</code> <code>int</code> <p>Maximum depth (higher values capped)</p> <code>100</code> <code>included_contigs</code> <code>Optional[Set[str]]</code> <p>Set of contigs to include</p> <code>None</code> <code>variant_classes</code> <code>Optional[List[VariantClass]]</code> <p>List of variant classes to count (default: [SNV])</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[int, AmbigGrid]</code> <p>Tuple of (ambiguous_count, grid_object)</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def count_ambiguous_sites(vcf_path: Path, dp_min: int, maf_min: float, \n                         dp_cap: int = 100, \n                         included_contigs: Optional[Set[str]] = None,\n                         variant_classes: Optional[List[VariantClass]] = None) -&gt; Tuple[int, AmbigGrid]:\n    \"\"\"\n    Count ambiguous sites from normalized VCF.\n\n    Args:\n        vcf_path: Path to normalized VCF file\n        dp_min: Minimum depth threshold\n        maf_min: Minimum MAF threshold  \n        dp_cap: Maximum depth (higher values capped)\n        included_contigs: Set of contigs to include\n        variant_classes: List of variant classes to count (default: [SNV])\n\n    Returns:\n        Tuple of (ambiguous_count, grid_object)\n    \"\"\"\n    if variant_classes is None:\n        variant_classes = [VariantClass.SNV]\n\n    grid = AmbigGrid(dp_cap=dp_cap)\n\n    # Process all sites and build grid\n    for site in parse_vcf_sites(vcf_path, included_contigs):\n        if site.variant_class in variant_classes:\n            grid.add_site(site.depth, site.maf)\n\n    # Count ambiguous sites\n    ambiguous_count = grid.count_at(dp_min, maf_min)\n\n    logger.info(f\"Found {ambiguous_count} ambiguous sites (dp&gt;={dp_min}, maf&gt;={maf_min})\")\n\n    return ambiguous_count, grid\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.emit_bed","title":"<code>emit_bed(normalized_vcf_path, output_path, dp_min, maf_min, sample_name, included_contigs=None)</code>","text":"<p>Emit BED output with ambiguous sites in 0-based half-open coordinates.</p> <p>BED format columns: chrom, start, end, name, score, strand, sample, variant_class, ref, alt, maf, dp, maf_bin, dp_cap</p> <p>Parameters:</p> Name Type Description Default <code>normalized_vcf_path</code> <code>Path</code> <p>Path to normalized input VCF</p> required <code>output_path</code> <code>Path</code> <p>Output BED path (will be bgzipped)</p> required <code>dp_min</code> <code>int</code> <p>Minimum depth threshold</p> required <code>maf_min</code> <code>float</code> <p>Minimum MAF threshold</p> required <code>sample_name</code> <code>str</code> <p>Sample name</p> required <code>included_contigs</code> <code>Optional[Set[str]]</code> <p>Set of contigs to include</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to compressed, indexed BED file</p> <p>Raises:</p> Type Description <code>VCFOperationError</code> <p>If emission fails</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def emit_bed(\n    normalized_vcf_path: Path,\n    output_path: Path,\n    dp_min: int,\n    maf_min: float,\n    sample_name: str,\n    included_contigs: Optional[Set[str]] = None\n) -&gt; Path:\n    \"\"\"\n    Emit BED output with ambiguous sites in 0-based half-open coordinates.\n\n    BED format columns:\n    chrom, start, end, name, score, strand, sample, variant_class, ref, alt, maf, dp, maf_bin, dp_cap\n\n    Args:\n        normalized_vcf_path: Path to normalized input VCF\n        output_path: Output BED path (will be bgzipped)\n        dp_min: Minimum depth threshold\n        maf_min: Minimum MAF threshold\n        sample_name: Sample name\n        included_contigs: Set of contigs to include\n\n    Returns:\n        Path to compressed, indexed BED file\n\n    Raises:\n        VCFOperationError: If emission fails\n    \"\"\"\n    try:\n        # Ensure output path has .bed.gz extension\n        if not str(output_path).endswith('.bed.gz'):\n            output_path = output_path.with_suffix('.bed.gz')\n\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n\n        bed_records = []\n\n        with pysam.VariantFile(str(normalized_vcf_path)) as input_vcf:\n            for record in input_vcf:\n                # Filter by included contigs\n                if included_contigs is not None and record.chrom not in included_contigs:\n                    continue\n\n                # Skip if no ALT alleles\n                if not record.alts:\n                    continue\n\n                # Process each ALT allele\n                for alt_allele in record.alts:\n                    # Skip if ref or alt is None\n                    if record.ref is None or alt_allele is None:\n                        continue\n\n                    variant_class = classify_variant(record.ref, alt_allele)\n\n                    # Skip unknown/symbolic variants\n                    if variant_class == VariantClass.UNKNOWN:\n                        continue\n\n                    # Extract MAF and depth\n                    maf = extract_maf_from_record(record)\n                    if maf is None:\n                        continue\n\n                    # Get depth\n                    depth = 0\n                    if \"DP\" in record.info:\n                        depth = record.info[\"DP\"]\n                    elif \"AD\" in record.format:\n                        samples = list(record.samples)\n                        if samples:\n                            sample = record.samples[samples[0]]\n                            ad = sample.get(\"AD\")\n                            if ad is not None:\n                                depth = sum(ad)\n\n                    # Check if passes thresholds\n                    passes_thresholds = depth &gt;= dp_min and maf &gt;= maf_min\n\n                    if passes_thresholds:\n                        # Convert to 0-based coordinates\n                        # VCF is 1-based, BED is 0-based half-open\n                        start = record.start  # pysam already converts to 0-based\n\n                        if variant_class == VariantClass.SNV:\n                            # SNV: 1bp interval\n                            end = start + 1\n                        elif variant_class == VariantClass.INS:\n                            # Insertion: 1bp anchor position\n                            end = start + 1\n                        elif variant_class == VariantClass.DEL:\n                            # Deletion: span the deleted bases\n                            if record.ref is not None:\n                                end = start + len(record.ref)\n                            else:\n                                end = start + 1\n                        else:\n                            end = start + 1\n\n                        # Create BED record\n                        name = f\"{record.chrom}:{record.pos}_{record.ref}&gt;{alt_allele}\"\n                        score = min(1000, int(1000 * maf))  # Scale MAF to 0-1000\n                        maf_bin = int(np.floor(100 * maf))\n\n                        bed_record = [\n                            record.chrom,           # chrom\n                            str(start),             # start (0-based)\n                            str(end),               # end (0-based half-open)\n                            name,                   # name\n                            str(score),             # score (0-1000)\n                            \".\",                    # strand (not applicable)\n                            sample_name,            # sample\n                            variant_class.value,    # variant_class\n                            record.ref,             # ref\n                            alt_allele,             # alt\n                            f\"{maf:.4f}\",          # maf\n                            str(depth),             # dp\n                            str(maf_bin),          # maf_bin\n                            \"100\"                   # dp_cap\n                        ]\n\n                        bed_records.append(bed_record)\n\n        # Sort records by chromosome and position\n        bed_records.sort(key=lambda x: (x[0], int(x[1])))\n\n        # Write BED file\n        temp_bed = output_path.with_suffix('.bed')\n        with open(temp_bed, 'w') as f:\n            # Write header comment\n            f.write(\"# chrom\\tstart\\tend\\tname\\tscore\\tstrand\\tsample\\tvariant_class\\tref\\talt\\tmaf\\tdp\\tmaf_bin\\tdp_cap\\n\")\n\n            # Write records\n            for record in bed_records:\n                f.write('\\t'.join(record) + '\\n')\n\n        # Compress with bgzip\n        bgzip_cmd = [\"bgzip\", \"-c\", str(temp_bed)]\n        with open(output_path, 'w') as f:\n            subprocess.run(bgzip_cmd, stdout=f, check=True)\n\n        # Remove temporary file\n        temp_bed.unlink()\n\n        # Index with tabix\n        tabix_cmd = [\"tabix\", \"-p\", \"bed\", str(output_path)]\n        subprocess.run(tabix_cmd, capture_output=True, text=True, check=True)\n\n        logger.info(f\"Emitted BED with {len(bed_records)} ambiguous sites: {output_path}\")\n        return output_path\n\n    except Exception as e:\n        error_msg = f\"BED emission failed: {str(e)}\"\n        logger.error(error_msg)\n        raise VCFOperationError(error_msg) from e\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.emit_matrix","title":"<code>emit_matrix(grid, output_path, sample_name)</code>","text":"<p>Emit variant matrix as compressed TSV.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>AmbigGrid</code> <p>Populated AmbigGrid with variant counts</p> required <code>output_path</code> <code>Path</code> <p>Output path (will be ensured to end with .tsv.gz)</p> required <code>sample_name</code> <code>str</code> <p>Sample name for logging</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to compressed matrix file</p> <p>Raises:</p> Type Description <code>VCFOperationError</code> <p>If matrix emission fails</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def emit_matrix(\n    grid: AmbigGrid,\n    output_path: Path,\n    sample_name: str\n) -&gt; Path:\n    \"\"\"\n    Emit variant matrix as compressed TSV.\n\n    Args:\n        grid: Populated AmbigGrid with variant counts\n        output_path: Output path (will be ensured to end with .tsv.gz)\n        sample_name: Sample name for logging\n\n    Returns:\n        Path to compressed matrix file\n\n    Raises:\n        VCFOperationError: If matrix emission fails\n    \"\"\"\n    try:\n        # Ensure output path has .tsv.gz extension\n        if not str(output_path).endswith('.tsv.gz'):\n            output_path = output_path.with_suffix('.tsv.gz')\n\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Write to temporary uncompressed file first\n        temp_tsv = output_path.with_suffix('.tsv')\n        grid.to_wide_tsv(temp_tsv)\n\n        # Compress with gzip\n        import gzip\n        with open(temp_tsv, 'rb') as f_in:\n            with gzip.open(output_path, 'wb') as f_out:\n                f_out.write(f_in.read())\n\n        # Remove temporary file\n        temp_tsv.unlink()\n\n        logger.info(f\"Emitted variant matrix for {sample_name}: {output_path}\")\n        return output_path\n\n    except Exception as e:\n        error_msg = f\"Matrix emission failed: {str(e)}\"\n        logger.error(error_msg)\n        raise VCFOperationError(error_msg) from e\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.emit_multiqc","title":"<code>emit_multiqc(sample_name, ambiguous_snv_count, breadth_10x, callable_bases, genome_length, dp_min, maf_min, mapper, caller, mode, output_path)</code>","text":"<p>Emit MultiQC-compatible metrics TSV.</p> <p>As per spec.md \u00a74.6: sample, ambiguous_snv_count, ambiguous_snv_per_mb, breadth_10x,  callable_bases, genome_length, dp_min, maf_min, mapper, caller, mode</p> <p>Parameters:</p> Name Type Description Default <code>sample_name</code> <code>str</code> <p>Sample identifier</p> required <code>ambiguous_snv_count</code> <code>int</code> <p>Count of ambiguous SNVs </p> required <code>breadth_10x</code> <code>float</code> <p>Fraction of genome with \u226510x coverage</p> required <code>callable_bases</code> <code>int</code> <p>Number of callable bases</p> required <code>genome_length</code> <code>int</code> <p>Total genome length</p> required <code>dp_min</code> <code>int</code> <p>Minimum depth threshold used</p> required <code>maf_min</code> <code>float</code> <p>Minimum MAF threshold used</p> required <code>mapper</code> <code>str</code> <p>Mapper tool name</p> required <code>caller</code> <code>str</code> <p>Caller tool name</p> required <code>mode</code> <code>str</code> <p>Analysis mode (self or ref)</p> required <code>output_path</code> <code>Path</code> <p>Output path (will be ensured to end with .tsv)</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to emitted MultiQC TSV file</p> <p>Raises:</p> Type Description <code>VCFOperationError</code> <p>If MultiQC emission fails</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def emit_multiqc(\n    sample_name: str,\n    ambiguous_snv_count: int,\n    breadth_10x: float,\n    callable_bases: int,\n    genome_length: int,\n    dp_min: int,\n    maf_min: float,\n    mapper: str,\n    caller: str,\n    mode: str,\n    output_path: Path\n) -&gt; Path:\n    \"\"\"\n    Emit MultiQC-compatible metrics TSV.\n\n    As per spec.md \u00a74.6: sample, ambiguous_snv_count, ambiguous_snv_per_mb, breadth_10x, \n    callable_bases, genome_length, dp_min, maf_min, mapper, caller, mode\n\n    Args:\n        sample_name: Sample identifier\n        ambiguous_snv_count: Count of ambiguous SNVs \n        breadth_10x: Fraction of genome with \u226510x coverage\n        callable_bases: Number of callable bases\n        genome_length: Total genome length\n        dp_min: Minimum depth threshold used\n        maf_min: Minimum MAF threshold used\n        mapper: Mapper tool name\n        caller: Caller tool name\n        mode: Analysis mode (self or ref)\n        output_path: Output path (will be ensured to end with .tsv)\n\n    Returns:\n        Path to emitted MultiQC TSV file\n\n    Raises:\n        VCFOperationError: If MultiQC emission fails\n    \"\"\"\n    try:\n        # Ensure output path has .tsv extension\n        if not str(output_path).endswith('.tsv'):\n            output_path = output_path.with_suffix('.tsv')\n\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Calculate ambiguous SNVs per megabase\n        # Per spec.md \u00a74.1: ambiguous_snv_per_mb = ambiguous_snv_count * 1e6 / callable_bases\n        ambiguous_snv_per_mb = (ambiguous_snv_count * 1_000_000) / callable_bases if callable_bases &gt; 0 else 0.0\n\n        with open(output_path, 'w') as f:\n            # Write header\n            header = [\n                \"sample\", \"ambiguous_snv_count\", \"ambiguous_snv_per_mb\", \"breadth_10x\",\n                \"callable_bases\", \"genome_length\", \"dp_min\", \"maf_min\", \"mapper\", \"caller\", \"mode\"\n            ]\n            f.write('\\t'.join(header) + '\\n')\n\n            # Write data row\n            row = [\n                sample_name,\n                str(ambiguous_snv_count),\n                f\"{ambiguous_snv_per_mb:.2f}\",\n                f\"{breadth_10x:.4f}\",\n                str(callable_bases),\n                str(genome_length),\n                str(dp_min),\n                f\"{maf_min:.3f}\",\n                mapper,\n                caller,\n                mode\n            ]\n            f.write('\\t'.join(row) + '\\n')\n\n        logger.info(f\"Emitted MultiQC metrics for {sample_name}: {output_path}\")\n        return output_path\n\n    except Exception as e:\n        error_msg = f\"MultiQC emission failed: {str(e)}\"\n        logger.error(error_msg)\n        raise VCFOperationError(error_msg) from e\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.emit_per_contig","title":"<code>emit_per_contig(normalized_vcf_path, depth_summary_path, output_path, dp_min, maf_min, sample_name, included_contigs=None)</code>","text":"<p>Emit per-contig summary statistics.</p> <p>Parameters:</p> Name Type Description Default <code>normalized_vcf_path</code> <code>Path</code> <p>Path to normalized VCF file</p> required <code>depth_summary_path</code> <code>Path</code> <p>Path to mosdepth summary file</p> required <code>output_path</code> <code>Path</code> <p>Output TSV path</p> required <code>dp_min</code> <code>int</code> <p>Minimum depth threshold</p> required <code>maf_min</code> <code>float</code> <p>Minimum MAF threshold</p> required <code>sample_name</code> <code>str</code> <p>Sample name</p> required <code>included_contigs</code> <code>Optional[Set[str]]</code> <p>Set of contigs to include</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to per-contig summary file</p> <p>Raises:</p> Type Description <code>VCFOperationError</code> <p>If emission fails</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def emit_per_contig(\n    normalized_vcf_path: Path,\n    depth_summary_path: Path,\n    output_path: Path,\n    dp_min: int,\n    maf_min: float,\n    sample_name: str,\n    included_contigs: Optional[Set[str]] = None\n) -&gt; Path:\n    \"\"\"\n    Emit per-contig summary statistics.\n\n    Args:\n        normalized_vcf_path: Path to normalized VCF file\n        depth_summary_path: Path to mosdepth summary file\n        output_path: Output TSV path\n        dp_min: Minimum depth threshold\n        maf_min: Minimum MAF threshold\n        sample_name: Sample name\n        included_contigs: Set of contigs to include\n\n    Returns:\n        Path to per-contig summary file\n\n    Raises:\n        VCFOperationError: If emission fails\n    \"\"\"\n    try:\n        from .depth import parse_mosdepth_summary\n\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Parse depth summary for contig-level stats\n        depth_summary = parse_mosdepth_summary(depth_summary_path)\n\n        # Count variants per contig\n        contig_variant_counts = {}\n\n        with pysam.VariantFile(str(normalized_vcf_path)) as vcf:\n            for record in vcf:\n                # Filter by included contigs\n                if included_contigs is not None and record.chrom not in included_contigs:\n                    continue\n\n                # Skip if no ALT alleles\n                if not record.alts:\n                    continue\n\n                # Initialize contig counts if needed\n                if record.chrom not in contig_variant_counts:\n                    contig_variant_counts[record.chrom] = {\n                        'snv': 0,\n                        'indel': 0,\n                        'del': 0\n                    }\n\n                # Process each ALT allele\n                for alt_allele in record.alts:\n                    if record.ref is None or alt_allele is None:\n                        continue\n\n                    variant_class = classify_variant(record.ref, alt_allele)\n\n                    if variant_class == VariantClass.UNKNOWN:\n                        continue\n\n                    # Extract MAF and depth\n                    maf = extract_maf_from_record(record)\n                    if maf is None:\n                        continue\n\n                    # Get depth\n                    depth = 0\n                    if \"DP\" in record.info:\n                        depth = int(record.info[\"DP\"])\n                    elif \"AD\" in record.format:\n                        samples = list(record.samples)\n                        if samples:\n                            sample = record.samples[samples[0]]\n                            ad = sample.get(\"AD\")\n                            if ad is not None:\n                                depth = sum(int(x) for x in ad)\n\n                    # Check if passes thresholds\n                    if depth &gt;= dp_min and maf &gt;= maf_min:\n                        if variant_class == VariantClass.SNV:\n                            contig_variant_counts[record.chrom]['snv'] += 1\n                        elif variant_class == VariantClass.INS:\n                            contig_variant_counts[record.chrom]['indel'] += 1\n                        elif variant_class == VariantClass.DEL:\n                            contig_variant_counts[record.chrom]['del'] += 1\n\n        # Write per-contig summary\n        with open(output_path, 'w') as f:\n            # Write header\n            header = [\n                \"sample\", \"contig\", \"length\", \"callable_bases_10x\", \"breadth_10x\",\n                \"ambiguous_snv_count\", \"ambiguous_indel_count\", \"ambiguous_del_count\",\n                \"ambiguous_snv_per_mb\", \"mean_depth\"\n            ]\n            f.write('\\t'.join(header) + '\\n')\n\n            # Write data for each contig in depth summary\n            for contig_stat in depth_summary.contig_stats:\n                contig_name = contig_stat.name\n                length = contig_stat.length\n                callable_bases = contig_stat.bases_covered\n                mean_depth = contig_stat.mean_depth\n                breadth_10x = contig_stat.breadth_10x\n\n                # Get variant counts for this contig\n                counts = contig_variant_counts.get(contig_name, {'snv': 0, 'indel': 0, 'del': 0})\n                snv_count = counts['snv']\n                indel_count = counts['indel']\n                del_count = counts['del']\n\n                # Calculate SNV per Mb - use callable_bases, not total length\n                # Per spec.md \u00a74.1: ambiguous_snv_per_mb = ambiguous_snv_count * 1e6 / callable_bases\n                snv_per_mb = (snv_count * 1_000_000) / callable_bases if callable_bases &gt; 0 else 0.0\n\n                row = [\n                    sample_name,\n                    contig_name,\n                    str(length),\n                    str(callable_bases),\n                    f\"{breadth_10x:.4f}\",\n                    str(snv_count),\n                    str(indel_count),\n                    str(del_count),\n                    f\"{snv_per_mb:.2f}\",\n                    f\"{mean_depth:.2f}\"\n                ]\n                f.write('\\t'.join(row) + '\\n')\n\n        logger.info(f\"Emitted per-contig summary for {sample_name}: {output_path}\")\n        return output_path\n\n    except Exception as e:\n        error_msg = f\"Per-contig summary emission failed: {str(e)}\"\n        logger.error(error_msg)\n        raise VCFOperationError(error_msg) from e\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.emit_vcf","title":"<code>emit_vcf(normalized_vcf_path, output_path, dp_min, maf_min, sample_name, require_pass=False, included_contigs=None)</code>","text":"<p>Emit VCF output with only records passing ambiguous site thresholds.</p> <p>Parameters:</p> Name Type Description Default <code>normalized_vcf_path</code> <code>Path</code> <p>Path to normalized input VCF</p> required <code>output_path</code> <code>Path</code> <p>Output VCF path (will be bgzipped)</p> required <code>dp_min</code> <code>int</code> <p>Minimum depth threshold</p> required <code>maf_min</code> <code>float</code> <p>Minimum MAF threshold</p> required <code>sample_name</code> <code>str</code> <p>Sample name for output</p> required <code>require_pass</code> <code>bool</code> <p>If True, include ORIG_FILTER info field</p> <code>False</code> <code>included_contigs</code> <code>Optional[Set[str]]</code> <p>Set of contigs to include</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to compressed, indexed VCF file</p> <p>Raises:</p> Type Description <code>VCFOperationError</code> <p>If emission fails</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def emit_vcf(\n    normalized_vcf_path: Path,\n    output_path: Path,\n    dp_min: int,\n    maf_min: float,\n    sample_name: str,\n    require_pass: bool = False,\n    included_contigs: Optional[Set[str]] = None\n) -&gt; Path:\n    \"\"\"\n    Emit VCF output with only records passing ambiguous site thresholds.\n\n    Args:\n        normalized_vcf_path: Path to normalized input VCF\n        output_path: Output VCF path (will be bgzipped)\n        dp_min: Minimum depth threshold\n        maf_min: Minimum MAF threshold\n        sample_name: Sample name for output\n        require_pass: If True, include ORIG_FILTER info field\n        included_contigs: Set of contigs to include\n\n    Returns:\n        Path to compressed, indexed VCF file\n\n    Raises:\n        VCFOperationError: If emission fails\n    \"\"\"\n    try:\n        # Ensure output path has .vcf.gz extension\n        if not str(output_path).endswith('.vcf.gz'):\n            output_path = output_path.with_suffix('.vcf.gz')\n\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n\n        with pysam.VariantFile(str(normalized_vcf_path)) as input_vcf:\n            # Create output VCF with enhanced header\n            header = input_vcf.header.copy()\n\n            # Add custom INFO fields\n            header.add_line('##INFO=&lt;ID=AMBIG,Number=0,Type=Flag,Description=\"Site passes ambiguous thresholds\"&gt;')\n            header.add_line('##INFO=&lt;ID=MAF,Number=1,Type=Float,Description=\"Minor allele frequency\"&gt;')\n            header.add_line('##INFO=&lt;ID=MAF_BIN,Number=1,Type=Integer,Description=\"MAF bin (floor(100*MAF))\"&gt;')\n            header.add_line('##INFO=&lt;ID=DP_CAP,Number=1,Type=Integer,Description=\"Depth cap used (100)\"&gt;')\n            header.add_line('##INFO=&lt;ID=VARIANT_CLASS,Number=1,Type=String,Description=\"Variant class (SNV/INS/DEL)\"&gt;')\n\n            if not require_pass:\n                header.add_line('##INFO=&lt;ID=ORIG_FILTER,Number=1,Type=String,Description=\"Original FILTER value\"&gt;')\n\n            # Add FILTER definitions\n            header.add_line('##FILTER=&lt;ID=PASS,Description=\"All filters passed\"&gt;')\n\n            with pysam.VariantFile(str(output_path), 'w', header=header) as output_vcf:\n                records_written = 0\n\n                for record in input_vcf:\n                    # Filter by included contigs\n                    if included_contigs is not None and record.chrom not in included_contigs:\n                        continue\n\n                    # Skip if no ALT alleles\n                    if not record.alts:\n                        continue\n\n                    # Process each ALT allele (though normalization should make these single)\n                    for alt_allele in record.alts:\n                        # Skip if ref or alt is None\n                        if record.ref is None or alt_allele is None:\n                            continue\n\n                        variant_class = classify_variant(record.ref, alt_allele)\n\n                        # Skip unknown/symbolic variants\n                        if variant_class == VariantClass.UNKNOWN:\n                            continue\n\n                        # Extract MAF and depth\n                        maf = extract_maf_from_record(record)\n                        if maf is None:\n                            continue\n\n                        # Get depth\n                        depth = 0\n                        if \"DP\" in record.info:\n                            depth = record.info[\"DP\"]\n                        elif \"AD\" in record.format:\n                            samples = list(record.samples)\n                            if samples:\n                                sample = record.samples[samples[0]]\n                                ad = sample.get(\"AD\")\n                                if ad is not None:\n                                    depth = sum(ad)\n\n                        # Check if passes thresholds\n                        passes_thresholds = depth &gt;= dp_min and maf &gt;= maf_min\n\n                        if passes_thresholds:\n                            # Create output record\n                            new_record = output_vcf.new_record(\n                                contig=record.chrom,\n                                start=record.start,\n                                stop=record.stop,\n                                alleles=(record.ref, alt_allele),\n                                id=record.id,\n                                qual=record.qual\n                            )\n\n                            # Copy existing INFO fields\n                            for key, value in record.info.items():\n                                new_record.info[key] = value\n\n                            # Add our custom INFO fields\n                            new_record.info[\"AMBIG\"] = True\n                            new_record.info[\"MAF\"] = round(maf, 4)\n                            new_record.info[\"MAF_BIN\"] = int(np.floor(100 * maf))\n                            new_record.info[\"DP_CAP\"] = 100\n                            new_record.info[\"VARIANT_CLASS\"] = variant_class.value\n\n                            if not require_pass:\n                                filter_keys = list(record.filter.keys())\n                                orig_filter = \";\".join(str(k) for k in filter_keys) if filter_keys else \"PASS\"\n                                new_record.info[\"ORIG_FILTER\"] = orig_filter\n\n                            # Set FILTER to PASS\n                            new_record.filter.clear()\n                            new_record.filter.add(\"PASS\")\n\n                            # Copy FORMAT fields\n                            for sample in record.samples:\n                                for key in record.format:\n                                    new_record.samples[sample][key] = record.samples[sample][key]\n\n                            output_vcf.write(new_record)\n                            records_written += 1\n\n        # Index the compressed VCF\n        tabix_cmd = [\"tabix\", \"-p\", \"vcf\", str(output_path)]\n        subprocess.run(tabix_cmd, capture_output=True, text=True, check=True)\n\n        logger.info(f\"Emitted VCF with {records_written} ambiguous sites: {output_path}\")\n        return output_path\n\n    except Exception as e:\n        error_msg = f\"VCF emission failed: {str(e)}\"\n        logger.error(error_msg)\n        raise VCFOperationError(error_msg) from e\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.extract_maf_from_record","title":"<code>extract_maf_from_record(record)</code>","text":"<p>Extract minor allele frequency from VCF record using precedence: AD \u2192 DP4 \u2192 AF.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <p>pysam VariantRecord</p> required <p>Returns:</p> Type Description <code>Optional[float]</code> <p>MAF as float between 0 and 1, or None if cannot be determined</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def extract_maf_from_record(record) -&gt; Optional[float]:\n    \"\"\"\n    Extract minor allele frequency from VCF record using precedence: AD \u2192 DP4 \u2192 AF.\n\n    Args:\n        record: pysam VariantRecord\n\n    Returns:\n        MAF as float between 0 and 1, or None if cannot be determined\n    \"\"\"\n    try:\n        # Precedence 1: FORMAT/AD (Allelic Depth)\n        if \"AD\" in record.format:\n            samples = list(record.samples)\n            if samples:\n                sample = record.samples[samples[0]]  # Single sample\n                ad = sample.get(\"AD\")\n                dp = sample.get(\"DP\")  # Total depth\n\n                if ad is not None and dp is not None:\n                    # Handle different AD formats\n                    if isinstance(ad, (list, tuple)) and len(ad) &gt;= 2:\n                        # Standard format: [ref_depth, alt_depth, ...]\n                        ref_depth = int(ad[0])\n                        alt_depth = sum(int(x) for x in ad[1:])  # Sum all alt alleles\n                        total_depth = ref_depth + alt_depth\n                    elif isinstance(ad, (int, str)):\n                        # BBTools format: AD is just alt_depth, use DP for total\n                        alt_depth = int(ad)\n                        total_depth = int(dp)\n                        ref_depth = total_depth - alt_depth\n                    else:\n                        # Skip if AD format is unexpected\n                        alt_depth = ref_depth = total_depth = 0\n\n                    if total_depth &gt; 0 and ref_depth &gt;= 0 and alt_depth &gt;= 0:\n                        ref_freq = ref_depth / total_depth\n                        alt_freq = alt_depth / total_depth\n                        return min(ref_freq, alt_freq)  # MAF is the minor frequency\n\n        # Precedence 2: INFO/DP4 (legacy format from bcftools/samtools)\n        if \"DP4\" in record.info:\n            dp4 = record.info[\"DP4\"]\n            if len(dp4) == 4:\n                ref_depth = int(dp4[0]) + int(dp4[1])  # Forward + reverse ref\n                alt_depth = int(dp4[2]) + int(dp4[3])  # Forward + reverse alt\n                total_depth = ref_depth + alt_depth\n                if total_depth &gt; 0:\n                    ref_freq = ref_depth / total_depth\n                    alt_freq = alt_depth / total_depth\n                    return min(ref_freq, alt_freq)\n\n        # Precedence 3: INFO/AF (Allele Frequency)\n        if \"AF\" in record.info:\n            af = record.info[\"AF\"]\n            if isinstance(af, (list, tuple)):\n                # Multi-allelic: compute site-level MAF\n                if len(af) &gt; 0:\n                    max_af = max(af)\n                    ref_freq = 1.0 - sum(af)\n                    return min(ref_freq, max_af)\n            else:\n                # Single alt allele\n                af_val = float(af)\n                ref_freq = 1.0 - af_val\n                return min(ref_freq, af_val)\n\n        # No MAF data available\n        warnings.warn(f\"No MAF data found for variant at {record.chrom}:{record.pos}\")\n        return None\n\n    except (ValueError, TypeError, KeyError) as e:\n        warnings.warn(f\"Error extracting MAF from {record.chrom}:{record.pos}: {e}\")\n        return None\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.normalize_and_split","title":"<code>normalize_and_split(vcf_in, reference, output_dir=None)</code>","text":"<p>Normalize VCF to reference and decompose into primitive records.</p> <p>Uses bcftools norm to: 1. Normalize variants to reference (-f REF) 2. Split multiallelic sites (-m -both) 3. Atomize variants (--atomize) 4. Compress and index output</p> <p>Parameters:</p> Name Type Description Default <code>vcf_in</code> <code>Path</code> <p>Input VCF file path</p> required <code>reference</code> <code>Path</code> <p>Reference FASTA file path</p> required <code>output_dir</code> <code>Optional[Path]</code> <p>Output directory (defaults to input directory)</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to normalized, compressed VCF file</p> <p>Raises:</p> Type Description <code>VCFOperationError</code> <p>If normalization fails</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def normalize_and_split(vcf_in: Path, reference: Path, \n                       output_dir: Optional[Path] = None) -&gt; Path:\n    \"\"\"\n    Normalize VCF to reference and decompose into primitive records.\n\n    Uses bcftools norm to:\n    1. Normalize variants to reference (-f REF)\n    2. Split multiallelic sites (-m -both)  \n    3. Atomize variants (--atomize)\n    4. Compress and index output\n\n    Args:\n        vcf_in: Input VCF file path\n        reference: Reference FASTA file path\n        output_dir: Output directory (defaults to input directory)\n\n    Returns:\n        Path to normalized, compressed VCF file\n\n    Raises:\n        VCFOperationError: If normalization fails\n    \"\"\"\n    if not check_vcf_tools():\n        raise VCFOperationError(\n            \"Required VCF tools not found. Need: bcftools, bgzip, tabix\"\n        )\n\n    if not vcf_in.exists():\n        raise VCFOperationError(f\"Input VCF file not found: {vcf_in}\")\n\n    if not reference.exists():\n        raise VCFOperationError(f\"Reference file not found: {reference}\")\n\n    # Determine output path\n    if output_dir is None:\n        output_dir = vcf_in.parent\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    normalized_vcf = output_dir / f\"{vcf_in.stem}.normalized.vcf.gz\"\n\n    try:\n        # Build bcftools norm command\n        cmd = [\n            \"bcftools\", \"norm\",\n            \"-f\", str(reference),\n            \"-m\", \"-both\",\n            \"--atomize\",\n            \"-cw\",  # Check REF alleles and warn about issues (instead of error)\n            \"-d\", \"exact\",  # Remove exact duplicates (replaces deprecated -D)\n            \"-O\", \"z\",  # Compress output\n            \"-o\", str(normalized_vcf),\n            str(vcf_in)\n        ]\n\n        logger.debug(f\"Running bcftools norm: {' '.join(cmd)}\")\n\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True\n        )\n\n        if result.stderr:\n            logger.debug(f\"bcftools norm stderr: {result.stderr}\")\n\n        # Index the compressed VCF\n        tabix_cmd = [\"tabix\", \"-p\", \"vcf\", str(normalized_vcf)]\n        logger.debug(f\"Indexing VCF: {' '.join(tabix_cmd)}\")\n\n        subprocess.run(\n            tabix_cmd,\n            capture_output=True,\n            text=True,\n            check=True\n        )\n\n        logger.info(f\"VCF normalized and indexed: {normalized_vcf}\")\n        return normalized_vcf\n\n    except subprocess.CalledProcessError as e:\n        error_msg = f\"VCF normalization failed: {e.stderr if e.stderr else str(e)}\"\n        logger.error(error_msg)\n        raise VCFOperationError(error_msg) from e\n    except Exception as e:\n        error_msg = f\"Unexpected error during VCF normalization: {str(e)}\"\n        logger.error(error_msg)\n        raise VCFOperationError(error_msg) from e\n</code></pre>"},{"location":"reference/#ssiamb.vcf_ops.parse_vcf_sites","title":"<code>parse_vcf_sites(vcf_path, included_contigs=None)</code>","text":"<p>Parse normalized VCF and yield site records with MAF and variant classification.</p> <p>Parameters:</p> Name Type Description Default <code>vcf_path</code> <code>Path</code> <p>Path to VCF file (can be compressed)</p> required <code>included_contigs</code> <code>Optional[Set[str]]</code> <p>Set of contig names to include (None = include all)</p> <code>None</code> <p>Yields:</p> Type Description <code>SiteRecord</code> <p>SiteRecord objects for each variant site</p> Source code in <code>src/ssiamb/vcf_ops.py</code> <pre><code>def parse_vcf_sites(vcf_path: Path, included_contigs: Optional[Set[str]] = None) -&gt; Iterator[SiteRecord]:\n    \"\"\"\n    Parse normalized VCF and yield site records with MAF and variant classification.\n\n    Args:\n        vcf_path: Path to VCF file (can be compressed)\n        included_contigs: Set of contig names to include (None = include all)\n\n    Yields:\n        SiteRecord objects for each variant site\n    \"\"\"\n    try:\n        with pysam.VariantFile(str(vcf_path)) as vcf:\n            for record in vcf:\n                # Filter by included contigs\n                if included_contigs is not None and record.chrom not in included_contigs:\n                    continue\n\n                # Skip if no ALT alleles\n                if not record.alts:\n                    continue\n\n                # For multi-allelic sites (after normalization should be rare),\n                # process each ALT allele separately\n                for alt_allele in record.alts:\n                    variant_class = classify_variant(record.ref, alt_allele)\n\n                    # Skip unknown/symbolic variants\n                    if variant_class == VariantClass.UNKNOWN:\n                        continue\n\n                    # Extract MAF\n                    maf = extract_maf_from_record(record)\n                    if maf is None:\n                        continue\n\n                    # Get depth from DP field or calculate from AD\n                    depth = 0\n                    if \"DP\" in record.info:\n                        depth = record.info[\"DP\"]\n                    elif \"AD\" in record.format:\n                        samples = list(record.samples)\n                        if samples:\n                            sample = record.samples[samples[0]]\n                            ad = sample.get(\"AD\")\n                            if ad is not None:\n                                depth = sum(ad)\n\n                    # Get original filter\n                    orig_filter = \";\".join(record.filter.keys()) if record.filter.keys() else \"PASS\"\n\n                    yield SiteRecord(\n                        chrom=record.chrom,\n                        pos=record.pos,\n                        ref=record.ref,\n                        alt=alt_allele,\n                        variant_class=variant_class,\n                        depth=depth,\n                        maf=maf,\n                        original_filter=orig_filter\n                    )\n\n    except Exception as e:\n        error_msg = f\"Error parsing VCF file {vcf_path}: {str(e)}\"\n        logger.error(error_msg)\n        raise VCFOperationError(error_msg) from e\n</code></pre>"},{"location":"reference/#io-utilities","title":"I/O Utilities","text":"<p>I/O utilities for ssiamb.</p> <p>This module provides file handling utilities including sample name validation, TSV writing with atomic operations, and file hashing.</p>"},{"location":"reference/#ssiamb.io_utils.SampleNameError","title":"<code>SampleNameError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when sample name is invalid.</p>"},{"location":"reference/#ssiamb.io_utils.TSVWriteError","title":"<code>TSVWriteError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when TSV writing fails.</p>"},{"location":"reference/#ssiamb.io_utils.compute_md5","title":"<code>compute_md5(file_path)</code>","text":"<p>Compute MD5 hash of a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to file</p> required <p>Returns:</p> Type Description <code>str</code> <p>MD5 hash as hex string</p> Source code in <code>src/ssiamb/io_utils.py</code> <pre><code>def compute_md5(file_path: Path) -&gt; str:\n    \"\"\"\n    Compute MD5 hash of a file.\n\n    Args:\n        file_path: Path to file\n\n    Returns:\n        MD5 hash as hex string\n    \"\"\"\n    hash_md5 = hashlib.md5()\n    with open(file_path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            hash_md5.update(chunk)\n    return hash_md5.hexdigest()\n</code></pre>"},{"location":"reference/#ssiamb.io_utils.file_lock","title":"<code>file_lock(file_path)</code>","text":"<p>Context manager for file locking (best-effort cross-platform).</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to lock</p> required Source code in <code>src/ssiamb/io_utils.py</code> <pre><code>@contextmanager\ndef file_lock(file_path: Path):\n    \"\"\"\n    Context manager for file locking (best-effort cross-platform).\n\n    Args:\n        file_path: Path to lock\n    \"\"\"\n    lock_file = file_path.with_suffix(file_path.suffix + \".lock\")\n\n    try:\n        with open(lock_file, \"w\") as f:\n            try:\n                fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)\n                yield\n            except (OSError, IOError):\n                # Lock failed - either file is locked or system doesn't support locks\n                # For now, just proceed (best effort)\n                yield\n    except (OSError, IOError):\n        # Can't create lock file - just proceed\n        yield\n    finally:\n        try:\n            lock_file.unlink(missing_ok=True)\n        except (OSError, IOError):\n            pass\n</code></pre>"},{"location":"reference/#ssiamb.io_utils.infer_sample_name","title":"<code>infer_sample_name(r1, r2=None, vcf=None, bam=None)</code>","text":"<p>Infer sample name from input filenames.</p> <p>Tries to extract a common prefix from R1/R2 filenames, removing common suffixes like _R1, _R2, .fastq, .gz, etc.</p> <p>Parameters:</p> Name Type Description Default <code>r1</code> <code>Path</code> <p>Forward reads file</p> required <code>r2</code> <code>Optional[Path]</code> <p>Reverse reads file (optional)</p> <code>None</code> <code>vcf</code> <code>Optional[Path]</code> <p>VCF file (optional)</p> <code>None</code> <code>bam</code> <code>Optional[Path]</code> <p>BAM file (optional)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Inferred sample name</p> <p>Raises:</p> Type Description <code>SampleNameError</code> <p>If sample name cannot be inferred</p> Source code in <code>src/ssiamb/io_utils.py</code> <pre><code>def infer_sample_name(\n    r1: Path,\n    r2: Optional[Path] = None,\n    vcf: Optional[Path] = None,\n    bam: Optional[Path] = None,\n) -&gt; str:\n    \"\"\"\n    Infer sample name from input filenames.\n\n    Tries to extract a common prefix from R1/R2 filenames, removing\n    common suffixes like _R1, _R2, .fastq, .gz, etc.\n\n    Args:\n        r1: Forward reads file\n        r2: Reverse reads file (optional)\n        vcf: VCF file (optional)\n        bam: BAM file (optional)\n\n    Returns:\n        Inferred sample name\n\n    Raises:\n        SampleNameError: If sample name cannot be inferred\n    \"\"\"\n    # Start with R1 filename (remove .gz first if present)\n    name = r1.name\n    if name.endswith('.gz'):\n        name = name[:-3]\n\n    # Remove .fastq extension\n    if name.endswith('.fastq'):\n        name = name[:-6]\n    elif name.endswith('.fq'):\n        name = name[:-3]\n\n    # Remove R1 suffix\n    for suffix in [\"_R1\", \"_1\", \".R1\", \".1\"]:\n        if name.endswith(suffix):\n            name = name[:-len(suffix)]\n            break\n\n    # If R2 provided, ensure it has a compatible name\n    if r2:\n        r2_name = r2.name\n        if r2_name.endswith('.gz'):\n            r2_name = r2_name[:-3]\n\n        # Remove .fastq extension\n        if r2_name.endswith('.fastq'):\n            r2_name = r2_name[:-6]\n        elif r2_name.endswith('.fq'):\n            r2_name = r2_name[:-3]\n\n        # Remove R2 suffix\n        for suffix in [\"_R2\", \"_2\", \".R2\", \".2\"]:\n            if r2_name.endswith(suffix):\n                r2_name = r2_name[:-len(suffix)]\n                break\n\n        # Check if R1 and R2 have the same base name\n        if name != r2_name:\n            raise SampleNameError(\n                f\"Cannot infer sample name: R1 stem '{name}' and \"\n                f\"R2 stem '{r2_name}' do not match\"\n            )\n\n    # Validate the inferred name\n    if not name:\n        raise SampleNameError(\"Cannot infer sample name: filename too short\")\n\n    try:\n        validate_sample_name(name)\n        return name\n    except SampleNameError as e:\n        raise SampleNameError(f\"Cannot infer valid sample name from '{r1}': {e}\")\n</code></pre>"},{"location":"reference/#ssiamb.io_utils.validate_sample_name","title":"<code>validate_sample_name(sample)</code>","text":"<p>Validate sample name according to ssiamb rules.</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>str</code> <p>Sample name to validate</p> required <p>Returns:</p> Type Description <code>str</code> <p>Validated sample name</p> <p>Raises:</p> Type Description <code>SampleNameError</code> <p>If sample name is invalid</p> Source code in <code>src/ssiamb/io_utils.py</code> <pre><code>def validate_sample_name(sample: str) -&gt; str:\n    \"\"\"\n    Validate sample name according to ssiamb rules.\n\n    Args:\n        sample: Sample name to validate\n\n    Returns:\n        Validated sample name\n\n    Raises:\n        SampleNameError: If sample name is invalid\n    \"\"\"\n    if not sample:\n        raise SampleNameError(\"Sample name cannot be empty\")\n\n    if not SAMPLE_NAME_PATTERN.match(sample):\n        raise SampleNameError(\n            f\"Sample name '{sample}' is invalid. \"\n            \"Must be 1-64 characters containing only letters, numbers, \"\n            \"periods, underscores, and hyphens.\"\n        )\n\n    return sample\n</code></pre>"},{"location":"reference/#ssiamb.io_utils.write_tsv_summary","title":"<code>write_tsv_summary(output_path, rows, mode=TSVMode.OVERWRITE)</code>","text":"<p>Write summary rows to TSV file with atomic operations.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>Path</code> <p>Output TSV file path</p> required <code>rows</code> <code>List[SummaryRow]</code> <p>List of SummaryRow objects to write</p> required <code>mode</code> <code>TSVMode</code> <p>Write mode (overwrite, append, or fail if exists)</p> <code>OVERWRITE</code> <p>Raises:</p> Type Description <code>TSVWriteError</code> <p>If writing fails</p> <code>FileExistsError</code> <p>If file exists and mode is FAIL</p> Source code in <code>src/ssiamb/io_utils.py</code> <pre><code>def write_tsv_summary(\n    output_path: Path,\n    rows: List[SummaryRow],\n    mode: TSVMode = TSVMode.OVERWRITE,\n) -&gt; None:\n    \"\"\"\n    Write summary rows to TSV file with atomic operations.\n\n    Args:\n        output_path: Output TSV file path\n        rows: List of SummaryRow objects to write\n        mode: Write mode (overwrite, append, or fail if exists)\n\n    Raises:\n        TSVWriteError: If writing fails\n        FileExistsError: If file exists and mode is FAIL\n    \"\"\"\n    if not rows:\n        raise TSVWriteError(\"No rows to write\")\n\n    # Check file existence and mode\n    file_exists = output_path.exists()\n\n    if mode == TSVMode.FAIL and file_exists:\n        raise FileExistsError(f\"Output file already exists: {output_path}\")\n\n    # Determine if we need to write header\n    write_header = (mode == TSVMode.OVERWRITE) or (mode == TSVMode.APPEND and not file_exists)\n\n    # For atomic writes, use temporary file\n    with file_lock(output_path):\n        if mode == TSVMode.APPEND and file_exists:\n            # Direct append\n            with open(output_path, \"a\", newline=\"\") as f:\n                writer = csv.DictWriter(f, fieldnames=rows[0].to_dict().keys(), delimiter=\"\\t\")\n                for row in rows:\n                    writer.writerow(row.to_dict())\n        else:\n            # Atomic write using temporary file\n            temp_file = None\n            try:\n                # Create temporary file in same directory\n                temp_fd, temp_path = tempfile.mkstemp(\n                    suffix=\".tmp\",\n                    prefix=output_path.name + \".\",\n                    dir=output_path.parent,\n                )\n                temp_file = Path(temp_path)\n\n                with os.fdopen(temp_fd, \"w\", newline=\"\") as f:\n                    writer = csv.DictWriter(f, fieldnames=rows[0].to_dict().keys(), delimiter=\"\\t\")\n\n                    if write_header:\n                        writer.writeheader()\n\n                    for row in rows:\n                        writer.writerow(row.to_dict())\n\n                # Atomic rename\n                temp_file.replace(output_path)\n                temp_file = None  # Successfully moved\n\n            except Exception as e:\n                if temp_file and temp_file.exists():\n                    temp_file.unlink()\n                raise TSVWriteError(f\"Failed to write TSV: {e}\") from e\n</code></pre>"},{"location":"reference/#ssiamb.io_utils.write_tsv_to_stdout","title":"<code>write_tsv_to_stdout(rows)</code>","text":"<p>Write summary rows to stdout in TSV format.</p> <p>Parameters:</p> Name Type Description Default <code>rows</code> <code>List[SummaryRow]</code> <p>List of SummaryRow objects to write</p> required Source code in <code>src/ssiamb/io_utils.py</code> <pre><code>def write_tsv_to_stdout(rows: List[SummaryRow]) -&gt; None:\n    \"\"\"\n    Write summary rows to stdout in TSV format.\n\n    Args:\n        rows: List of SummaryRow objects to write\n    \"\"\"\n    import sys\n\n    if not rows:\n        return\n\n    writer = csv.DictWriter(sys.stdout, fieldnames=rows[0].to_dict().keys(), delimiter=\"\\t\")\n    writer.writeheader()\n\n    for row in rows:\n        writer.writerow(row.to_dict())\n</code></pre>"},{"location":"reference/#models","title":"Models","text":"<p>Core data models for ssiamb.</p> <p>This module defines the primary data structures used throughout the application, including configuration objects, output records, and enums for various options.</p>"},{"location":"reference/#ssiamb.models.Caller","title":"<code>Caller</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Variant calling tool.</p>"},{"location":"reference/#ssiamb.models.DepthTool","title":"<code>DepthTool</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Depth analysis tool.</p>"},{"location":"reference/#ssiamb.models.Mapper","title":"<code>Mapper</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Read mapping tool.</p>"},{"location":"reference/#ssiamb.models.Mode","title":"<code>Mode</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Analysis mode.</p>"},{"location":"reference/#ssiamb.models.OnFail","title":"<code>OnFail</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Action when reference resolution fails.</p>"},{"location":"reference/#ssiamb.models.Paths","title":"<code>Paths(r1, r2, assembly=None, reference=None, output_dir=Path('.'), sample=None, bam=None, vcf=None, depth_summary=None)</code>  <code>dataclass</code>","text":"<p>File paths for input and output.</p>"},{"location":"reference/#ssiamb.models.Paths.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Validate paths and resolve output directory.</p> Source code in <code>src/ssiamb/models.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Validate paths and resolve output directory.\"\"\"\n    if not self.r1.exists():\n        raise FileNotFoundError(f\"R1 file not found: {self.r1}\")\n    if not self.r2.exists():\n        raise FileNotFoundError(f\"R2 file not found: {self.r2}\")\n\n    # Ensure output directory exists\n    self.output_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/#ssiamb.models.Provenance","title":"<code>Provenance(ssiamb_version, command_line, timestamp, input_files=dict(), tool_versions=dict(), hostname='', working_dir='')</code>  <code>dataclass</code>","text":"<p>Provenance information for reproducibility.</p> <p>Tracks tool versions, command lines, input file hashes, etc.</p>"},{"location":"reference/#ssiamb.models.Provenance.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary for JSON output.</p> Source code in <code>src/ssiamb/models.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert to dictionary for JSON output.\"\"\"\n    return {\n        \"ssiamb_version\": self.ssiamb_version,\n        \"command_line\": self.command_line,\n        \"timestamp\": self.timestamp,\n        \"input_files\": self.input_files,\n        \"tool_versions\": self.tool_versions,\n        \"hostname\": self.hostname,\n        \"working_dir\": self.working_dir,\n    }\n</code></pre>"},{"location":"reference/#ssiamb.models.RunPlan","title":"<code>RunPlan(mode, sample, paths, thresholds, mapper=Mapper.MINIMAP2, caller=Caller.BBTOOLS, depth_tool=DepthTool.MOSDEPTH, bbtools_mem=None, require_pass=False, ref_source='unknown', ref_label='unknown', emit_vcf=False, emit_bed=False, emit_matrix=False, emit_per_contig=False, emit_provenance=False, emit_multiqc=False, to_stdout=False, tsv_mode=TSVMode.OVERWRITE, threads=1, dry_run=False)</code>  <code>dataclass</code>","text":"<p>Complete execution plan for a ssiamb run.</p> <p>This captures all resolved inputs, tools, and output specifications before execution begins.</p>"},{"location":"reference/#ssiamb.models.RunPlan.get_sample_prefix","title":"<code>get_sample_prefix()</code>","text":"<p>Get prefix for output files.</p> Source code in <code>src/ssiamb/models.py</code> <pre><code>def get_sample_prefix(self) -&gt; str:\n    \"\"\"Get prefix for output files.\"\"\"\n    return f\"{self.sample}_{self.mode.value}\"\n</code></pre>"},{"location":"reference/#ssiamb.models.SummaryRow","title":"<code>SummaryRow(sample, mode, mapper, caller, dp_min, maf_min, dp_cap, denom_policy, callable_bases, genome_length, breadth_10x, ambiguous_snv_count, ambiguous_snv_per_mb, ambiguous_indel_count, ambiguous_del_count, ref_label, ref_accession, bracken_species, bracken_frac, bracken_reads, alias_used, reused_bam, reused_vcf, runtime_sec, tool_version)</code>  <code>dataclass</code>","text":"<p>Single row of the ambiguous_summary.tsv output.</p> <p>Based on spec.md \u00a74.1 - Primary Output Format. Schema: sample, mode, mapper, caller, dp_min, maf_min, dp_cap, denom_policy, callable_bases, genome_length, breadth_10x, ambiguous_snv_count, ambiguous_snv_per_mb, ambiguous_indel_count, ambiguous_del_count, ref_label, ref_accession, bracken_species, bracken_frac, bracken_reads, alias_used, reused_bam, reused_vcf, runtime_sec, tool_version</p>"},{"location":"reference/#ssiamb.models.SummaryRow.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dictionary for TSV output.</p> Source code in <code>src/ssiamb/models.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert to dictionary for TSV output.\"\"\"\n    return {\n        \"sample\": self.sample,\n        \"mode\": self.mode,\n        \"mapper\": self.mapper,\n        \"caller\": self.caller,\n        \"dp_min\": self.dp_min,\n        \"maf_min\": self.maf_min,\n        \"dp_cap\": self.dp_cap,\n        \"denom_policy\": self.denom_policy,\n        \"callable_bases\": self.callable_bases,\n        \"genome_length\": self.genome_length,\n        \"breadth_10x\": f\"{self.breadth_10x:.4f}\",\n        \"ambiguous_snv_count\": self.ambiguous_snv_count,\n        \"ambiguous_snv_per_mb\": f\"{self.ambiguous_snv_per_mb:.2f}\",\n        \"ambiguous_indel_count\": self.ambiguous_indel_count,\n        \"ambiguous_del_count\": self.ambiguous_del_count,\n        \"ref_label\": self.ref_label,\n        \"ref_accession\": self.ref_accession,\n        \"bracken_species\": self.bracken_species,\n        \"bracken_frac\": self.bracken_frac,\n        \"bracken_reads\": self.bracken_reads,\n        \"alias_used\": self.alias_used,\n        \"reused_bam\": self.reused_bam,\n        \"reused_vcf\": self.reused_vcf,\n        \"runtime_sec\": self.runtime_sec,\n        \"tool_version\": self.tool_version,\n    }\n</code></pre>"},{"location":"reference/#ssiamb.models.TSVMode","title":"<code>TSVMode</code>","text":"<p>               Bases: <code>Enum</code></p> <p>TSV output mode.</p>"},{"location":"reference/#ssiamb.models.Thresholds","title":"<code>Thresholds(dp_min=None, maf_min=None, dp_cap=None, mapq_min=None, baseq_min=None)</code>  <code>dataclass</code>","text":"<p>Thresholds for ambiguous site detection.</p>"},{"location":"reference/#ssiamb.models.Thresholds.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Load defaults from configuration and validate threshold values.</p> Source code in <code>src/ssiamb/models.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Load defaults from configuration and validate threshold values.\"\"\"\n    # Import here to avoid circular imports\n    from .config import get_config\n\n    # Load defaults from config if not explicitly set\n    config = get_config()\n    if self.dp_min is None:\n        self.dp_min = config.get_threshold(\"dp_min\", 10)\n    if self.maf_min is None:\n        self.maf_min = config.get_threshold(\"maf_min\", 0.1)\n    if self.dp_cap is None:\n        self.dp_cap = config.get_threshold(\"dp_cap\", 100)\n    if self.mapq_min is None:\n        self.mapq_min = config.get_threshold(\"mapq_min\", 20)\n    if self.baseq_min is None:\n        self.baseq_min = config.get_threshold(\"baseq_min\", 20)\n\n    # Validate threshold values (now they should all be set)\n    assert self.dp_min is not None\n    assert self.maf_min is not None\n    assert self.dp_cap is not None\n    assert self.mapq_min is not None\n    assert self.baseq_min is not None\n\n    if self.dp_min &lt; 1:\n        raise ValueError(\"dp_min must be &gt;= 1\")\n    if not 0.0 &lt;= self.maf_min &lt;= 1.0:\n        raise ValueError(\"maf_min must be between 0.0 and 1.0\")\n    if self.dp_cap &lt; self.dp_min:\n        raise ValueError(\"dp_cap must be &gt;= dp_min\")\n    if self.mapq_min &lt; 0:\n        raise ValueError(\"mapq_min must be &gt;= 0\")\n    if self.baseq_min &lt; 0:\n        raise ValueError(\"baseq_min must be &gt;= 0\")\n</code></pre>"},{"location":"reference/#ssiamb.models.Thresholds.from_config","title":"<code>from_config(config=None, **overrides)</code>  <code>classmethod</code>","text":"<p>Create Thresholds from configuration with optional overrides.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Optional['SsiambConfig']</code> <p>Configuration object (uses global if None)</p> <code>None</code> <code>**overrides</code> <p>Explicit threshold values to override</p> <code>{}</code> <p>Returns:</p> Type Description <code>'Thresholds'</code> <p>Thresholds instance with config defaults and overrides applied</p> Source code in <code>src/ssiamb/models.py</code> <pre><code>@classmethod\ndef from_config(cls, config: Optional[\"SsiambConfig\"] = None, **overrides) -&gt; \"Thresholds\":\n    \"\"\"\n    Create Thresholds from configuration with optional overrides.\n\n    Args:\n        config: Configuration object (uses global if None)\n        **overrides: Explicit threshold values to override\n\n    Returns:\n        Thresholds instance with config defaults and overrides applied\n    \"\"\"\n    if config is None:\n        from .config import get_config\n        config = get_config()\n\n    # Start with config defaults\n    kwargs = {\n        \"dp_min\": config.get_threshold(\"dp_min\", 10),\n        \"maf_min\": config.get_threshold(\"maf_min\", 0.1),\n        \"dp_cap\": config.get_threshold(\"dp_cap\", 100),\n        \"mapq_min\": config.get_threshold(\"mapq_min\", 20),\n        \"baseq_min\": config.get_threshold(\"baseq_min\", 20),\n    }\n\n    # Apply overrides\n    kwargs.update(overrides)\n\n    return cls(**kwargs)\n</code></pre>"},{"location":"reference/#provenance","title":"Provenance","text":"<p>Provenance tracking for ssiamb runs.</p> <p>This module handles collection and output of detailed per-sample provenance information when --emit-provenance is used.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceCallerParams","title":"<code>ProvenanceCallerParams(exact_cmdlines)</code>  <code>dataclass</code>","text":"<p>Variant caller parameters.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceContigFilters","title":"<code>ProvenanceContigFilters(min_contig_len=500)</code>  <code>dataclass</code>","text":"<p>Contig filtering settings.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceCounts","title":"<code>ProvenanceCounts(ambiguous_snv_count=None, ambiguous_indel_count=None, ambiguous_del_count=None, callable_bases=None, genome_length=None)</code>  <code>dataclass</code>","text":"<p>Analysis counts.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceDuplicatePolicy","title":"<code>ProvenanceDuplicatePolicy(denominator_excludes_dups=True, bam_had_dups_flag=None)</code>  <code>dataclass</code>","text":"<p>Duplicate handling policy.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceExtrasEmitted","title":"<code>ProvenanceExtrasEmitted(vcf=False, bed=False, matrix=False, per_contig=False)</code>  <code>dataclass</code>","text":"<p>Optional outputs emitted.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceGridCell","title":"<code>ProvenanceGridCell(depth, maf_bin)</code>  <code>dataclass</code>","text":"<p>Grid cell used for analysis.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceInput","title":"<code>ProvenanceInput(path, md5=None)</code>  <code>dataclass</code>","text":"<p>Input file information with MD5 hash.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceMappingStats","title":"<code>ProvenanceMappingStats(total_reads=None, mapped_reads=None, map_rate=None, mean_depth=None, breadth_1x=None, breadth_10x=None)</code>  <code>dataclass</code>","text":"<p>Mapping statistics.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceRecord","title":"<code>ProvenanceRecord(tool_version, python_version, conda_env, started_at, finished_at, runtime_sec, threads, sample, mode, mapper, caller, thresholds, denom_policy, depth_tool, inputs, reference_info, species_selection=None, mapping_stats=None, duplicate_policy=None, contig_filters=None, caller_params=None, counts=None, grid_cell_used=None, extras_emitted=None, warnings=None)</code>  <code>dataclass</code>","text":"<p>Complete provenance record for a sample.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceReferenceInfo","title":"<code>ProvenanceReferenceInfo(species_requested=None, alias_applied=None, species_final=None, fasta_path=None, fasta_md5=None, source=None)</code>  <code>dataclass</code>","text":"<p>Reference genome information.</p>"},{"location":"reference/#ssiamb.provenance.ProvenanceSpeciesSelection","title":"<code>ProvenanceSpeciesSelection(bracken_species=None, bracken_frac=None, bracken_reads=None, thresholds=None, on_fail=None)</code>  <code>dataclass</code>","text":"<p>Species selection from Bracken.</p>"},{"location":"reference/#ssiamb.provenance.calculate_md5","title":"<code>calculate_md5(file_path)</code>","text":"<p>Calculate MD5 hash of a file.</p> Source code in <code>src/ssiamb/provenance.py</code> <pre><code>def calculate_md5(file_path: Path) -&gt; Optional[str]:\n    \"\"\"Calculate MD5 hash of a file.\"\"\"\n    hash_md5 = hashlib.md5()\n    try:\n        with open(file_path, \"rb\") as f:\n            for chunk in iter(lambda: f.read(4096), b\"\"):\n                hash_md5.update(chunk)\n        return hash_md5.hexdigest()\n    except (FileNotFoundError, PermissionError):\n        return None\n</code></pre>"},{"location":"reference/#ssiamb.provenance.create_provenance_record","title":"<code>create_provenance_record(sample, mode, started_at, finished_at, threads, mapper, caller, dp_min, maf_min, dp_cap, denom_policy, depth_tool, emit_vcf, emit_bed, emit_matrix, emit_per_contig, r1=None, r2=None, assembly=None, reference=None, bam=None, vcf=None, species=None, mapping_stats=None, species_selection=None, counts=None, warnings=None, reference_path=None, reference_species=None)</code>","text":"<p>Create a complete provenance record for a sample.</p> Source code in <code>src/ssiamb/provenance.py</code> <pre><code>def create_provenance_record(\n    sample: str,\n    mode: Mode,\n    started_at: datetime,\n    finished_at: datetime,\n    threads: int,\n    mapper: str,\n    caller: str,\n    dp_min: int,\n    maf_min: float,\n    dp_cap: int,\n    denom_policy: str,\n    depth_tool: str,\n    emit_vcf: bool,\n    emit_bed: bool,\n    emit_matrix: bool,\n    emit_per_contig: bool,\n    r1: Optional[Path] = None,\n    r2: Optional[Path] = None,\n    assembly: Optional[Path] = None,\n    reference: Optional[Path] = None,\n    bam: Optional[Path] = None,\n    vcf: Optional[Path] = None,\n    species: Optional[str] = None,\n    mapping_stats: Optional[ProvenanceMappingStats] = None,\n    species_selection: Optional[ProvenanceSpeciesSelection] = None,\n    counts: Optional[ProvenanceCounts] = None,\n    warnings: Optional[List[QCWarning]] = None,\n    reference_path: Optional[Path] = None,\n    reference_species: Optional[str] = None,\n) -&gt; ProvenanceRecord:\n    \"\"\"Create a complete provenance record for a sample.\"\"\"\n\n    # Calculate runtime\n    runtime_sec = (finished_at - started_at).total_seconds()\n\n    # Prepare inputs\n    inputs = {}\n    if r1:\n        inputs[\"r1\"] = {\"path\": str(r1), \"md5\": calculate_md5(r1)}\n    if r2:\n        inputs[\"r2\"] = {\"path\": str(r2), \"md5\": calculate_md5(r2)}\n    if assembly:\n        inputs[\"assembly\"] = {\"path\": str(assembly), \"md5\": calculate_md5(assembly)}\n    if reference:\n        inputs[\"reference\"] = {\"path\": str(reference), \"md5\": calculate_md5(reference)}\n    if bam:\n        inputs[\"bam\"] = {\"path\": str(bam), \"md5\": calculate_md5(bam)}\n    if vcf:\n        inputs[\"vcf\"] = {\"path\": str(vcf), \"md5\": calculate_md5(vcf)}\n\n    # Reference info\n    reference_info = {}\n    if mode == Mode.REF:\n        reference_info[\"species_requested\"] = species\n        reference_info[\"species_final\"] = reference_species\n        if reference_path:\n            reference_info[\"fasta_path\"] = str(reference_path)\n            reference_info[\"fasta_md5\"] = calculate_md5(reference_path)\n\n    # Grid cell used\n    grid_cell = {\n        \"depth\": dp_min,\n        \"maf_bin\": int(maf_min * 100)  # Floor of 100 * maf_min\n    }\n\n    # Extras emitted\n    extras = {\n        \"vcf\": emit_vcf,\n        \"bed\": emit_bed,\n        \"matrix\": emit_matrix,\n        \"per_contig\": emit_per_contig\n    }\n\n    # Convert warnings to string list\n    warning_messages = []\n    if warnings:\n        warning_messages = [f\"{w.metric}: {w.message}\" for w in warnings]\n\n    return ProvenanceRecord(\n        tool_version=get_tool_version(),\n        python_version=f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n        conda_env=get_conda_env(),\n        started_at=started_at.isoformat(),\n        finished_at=finished_at.isoformat(),\n        runtime_sec=runtime_sec,\n        threads=threads,\n        sample=sample,\n        mode=mode.value,\n        mapper=mapper,\n        caller=caller,\n        thresholds={\n            \"dp_min\": dp_min,\n            \"maf_min\": maf_min,\n            \"dp_cap\": dp_cap\n        },\n        denom_policy=denom_policy,\n        depth_tool=depth_tool,\n        inputs=inputs,\n        reference_info=reference_info,\n        species_selection=asdict(species_selection) if species_selection else None,\n        mapping_stats=asdict(mapping_stats) if mapping_stats else None,\n        duplicate_policy=asdict(ProvenanceDuplicatePolicy()) if mode == Mode.SELF else None,\n        contig_filters=asdict(ProvenanceContigFilters(min_contig_len=500)),\n        caller_params={\"exact_cmdlines\": []},  # TODO: Collect actual command lines\n        counts=asdict(counts) if counts else {},\n        grid_cell_used=grid_cell,\n        extras_emitted=extras,\n        warnings=warning_messages\n    )\n</code></pre>"},{"location":"reference/#ssiamb.provenance.get_conda_env","title":"<code>get_conda_env()</code>","text":"<p>Get the name of the current conda environment.</p> Source code in <code>src/ssiamb/provenance.py</code> <pre><code>def get_conda_env() -&gt; Optional[str]:\n    \"\"\"Get the name of the current conda environment.\"\"\"\n    conda_env = os.environ.get('CONDA_DEFAULT_ENV')\n    if conda_env and conda_env != 'base':\n        return conda_env\n    return None\n</code></pre>"},{"location":"reference/#ssiamb.provenance.get_tool_version","title":"<code>get_tool_version()</code>","text":"<p>Get the current tool version.</p> Source code in <code>src/ssiamb/provenance.py</code> <pre><code>def get_tool_version() -&gt; str:\n    \"\"\"Get the current tool version.\"\"\"\n    try:\n        from importlib.metadata import version\n        return version('ssiamb')\n    except Exception:\n        return \"unknown\"\n</code></pre>"},{"location":"reference/#ssiamb.provenance.write_provenance_json","title":"<code>write_provenance_json(records, output_path)</code>","text":"<p>Write provenance records to JSON file.</p> Source code in <code>src/ssiamb/provenance.py</code> <pre><code>def write_provenance_json(records: List[ProvenanceRecord], output_path: Path) -&gt; None:\n    \"\"\"Write provenance records to JSON file.\"\"\"\n    with open(output_path, 'w') as f:\n        json.dump([asdict(record) for record in records], f, indent=2)\n</code></pre>"}]}